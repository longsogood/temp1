import streamlit as st
import pandas as pd
import requests
import time
import datetime
import os
import pickle
import schedule
import threading
from uuid import uuid4
import concurrent.futures
import logging

## C·∫•u h√¨nh streamlit
st.set_page_config(
    layout="wide",
    page_title="Agent HR N·ªôi b·ªô",
    page_icon="‚ú®"
)


# C·∫•u h√¨nh logging
log_file = "logs/test_log.log"
os.makedirs(os.path.dirname(log_file), exist_ok=True)
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
file_handler = logging.FileHandler(log_file, encoding='utf-8')
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
file_handler.setFormatter(formatter)
if not logger.handlers:
    logger.addHandler(file_handler)

# Global site variable - ƒë∆∞·ª£c set d·ª±a tr√™n trang hi·ªán t·∫°i
SITE = "Agent HR N·ªôi b·ªô"

# Kh·ªüi t·∫°o session state
if 'results' not in st.session_state:
    st.session_state.results = None
if 'schedule_enabled' not in st.session_state:
    st.session_state.schedule_enabled = {}
if 'schedule_thread' not in st.session_state:
    st.session_state.schedule_thread = {}
if 'test_history' not in st.session_state:
    st.session_state.test_history = {}
if 'failed_tests' not in st.session_state:
    st.session_state.failed_tests = {}
if 'test_changes_history' not in st.session_state:
    st.session_state.test_changes_history = {}
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = None

# ƒê∆∞·ªùng d·∫´n file
RESULTS_DIR = "test_results"
FAILED_TESTS_FILE = os.path.join(RESULTS_DIR, "failed_tests.pkl")
TEST_HISTORY_FILE = os.path.join(RESULTS_DIR, "test_history.pkl")
TEST_CHANGES_FILE = os.path.join(RESULTS_DIR, "test_changes.pkl")

# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
os.makedirs(RESULTS_DIR, exist_ok=True)

# --- C√°c h√†m x·ª≠ l√Ω ---
def get_current_site():
    """Get current site from global variable"""
    return SITE

def filter_results(results, threshold, criterion, filter_type):
    filtered_data = []
    for result in results:
        score = result["evaluate_result"]["scores"].get(criterion, 0)
        if (filter_type == "greater" and score >= threshold) or \
           (filter_type == "less" and score <= threshold):
            filtered_data.append(result)
    return filtered_data

def save_test_results(results, test_name, site):
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    filename = f"{test_name}_{timestamp}.xlsx"
    filepath = os.path.join(RESULTS_DIR, site, filename)
    os.makedirs(os.path.dirname(filepath), exist_ok=True)

    df = pd.DataFrame(results)
    df.to_excel(filepath, index=False)

    # Ph√¢n lo·∫°i k·∫øt qu·∫£ chi ti·∫øt
    fail_criterion = st.session_state.get("fail_criterion", "accuracy")
    fail_threshold = st.session_state.get("fail_threshold", 8.0)
    
    num_passed = 0
    num_failed_api = 0
    num_failed_extract = 0
    num_failed_accuracy = 0
    
    for r in results:
        if "failed_details" in r:
            reason = r["failed_details"].get("reason", "")
            if "API" in reason or "Exception" in reason:
                num_failed_api += 1
            elif "evaluate_result" in reason:
                num_failed_extract += 1
            else:
                num_failed_accuracy += 1
        else:
            # Ki·ªÉm tra ti√™u ch√≠ fail
            criterion_score = r["evaluate_result"]["scores"].get(fail_criterion, 0)
            if criterion_score >= fail_threshold:
                num_passed += 1
            else:
                num_failed_accuracy += 1
    
    num_failed = num_failed_api + num_failed_extract + num_failed_accuracy

    history_entry = {
        "timestamp": timestamp,
        "test_name": test_name,
        "num_questions": len(results),
        "num_passed": num_passed,
        "num_failed": num_failed,
        "num_failed_api": num_failed_api,
        "num_failed_extract": num_failed_extract,
        "num_failed_accuracy": num_failed_accuracy,
        "filename": filename
    }

    # Initialize test_history if not exists
    try:
        if 'test_history' not in st.session_state:
            st.session_state.test_history = {}
        if site not in st.session_state.test_history:
            st.session_state.test_history[site] = []
        st.session_state.test_history[site].append(history_entry)

        site_paths = get_site_paths(site)
        with open(site_paths["test_history"], "wb") as f:
            pickle.dump(st.session_state.test_history[site], f)
    except Exception as e:
        logger.warning(f"Kh√¥ng th·ªÉ l∆∞u l·ªãch s·ª≠ test: {str(e)}")

    return filepath

def save_failed_test_details(failed_results, site=None):
    # Use provided site or fallback to session state
    if site is None:
        site = get_current_site()
    
    # Initialize failed_tests if not exists
    if 'failed_tests' not in st.session_state:
        st.session_state.failed_tests = {}
    
    if site not in st.session_state.failed_tests:
        st.session_state.failed_tests[site] = []

    for result in failed_results:
        st.session_state.failed_tests[site].append(result)

    site_paths = get_site_paths(site)
    with open(site_paths["failed_tests"], "wb") as f:
        pickle.dump(st.session_state.failed_tests[site], f)

def run_scheduled_test(file_path, test_name, site, api_url, evaluate_api_url):
    logger.info(f"B·∫Øt ƒë·∫ßu ch·∫°y test theo l·ªãch: {test_name} cho site {site} v·ªõi API {api_url}")
    
    # Initialize session state for scheduled context if needed
    try:
        if 'failed_tests' not in st.session_state:
            st.session_state.failed_tests = {}
        if 'test_history' not in st.session_state:
            st.session_state.test_history = {}
        if 'test_changes_history' not in st.session_state:
            st.session_state.test_changes_history = {}
    except Exception as e:
        logger.warning(f"Kh√¥ng th·ªÉ kh·ªüi t·∫°o session state: {str(e)}")
    
    try:
        abs_path = os.path.abspath(file_path)
        if not os.path.exists(abs_path):
            logger.error(f"File test kh√¥ng t·ªìn t·∫°i: {abs_path}")
            return
        logger.info(f"ƒê·ªçc file test: {abs_path}")
    except Exception as e:
        logger.error(f"L·ªói khi ki·ªÉm tra file test: {str(e)}")
        return
    try:
        df = pd.read_excel(abs_path)
        questions = df.iloc[:, 0].tolist()
        true_answers = df.iloc[:, 1].tolist()
        logger.info(f"S·ªë c√¢u h·ªèi ƒë·ªçc ƒë∆∞·ª£c: {len(questions)} | S·ªë ƒë√°p √°n: {len(true_answers)}")

        results, failed_questions = process_questions_batch(
            questions, 
            true_answers, 
            test_name=test_name, 
            is_scheduled=True,
            site=site,
            api_url=api_url,
            evaluate_api_url=evaluate_api_url
        )

        try:
            # Lu√¥n c·ªë g·∫Øng l∆∞u file k·∫øt qu·∫£ ƒë·ªÉ thu·∫≠n ti·ªán ki·ªÉm tra, k·ªÉ c·∫£ khi r·ªóng
            saved_path = save_test_results(results or [], test_name, site)
            logger.info(f"ƒê√£ l∆∞u k·∫øt qu·∫£ test: {test_name} ‚Üí {os.path.abspath(saved_path)}")
        except Exception as e:
            logger.error(f"L·ªói khi l∆∞u k·∫øt qu·∫£ test {test_name}: {str(e)}")
        if failed_questions:
            logger.warning(f"C√≥ {len(failed_questions)} c√¢u h·ªèi th·∫•t b·∫°i trong test: {test_name}")

    except Exception as e:
        logger.error(f"L·ªói khi ch·∫°y test theo l·ªãch {test_name}: {str(e)}")

def schedule_manager():
    while True:
        schedule.run_pending()
        time.sleep(1)

def setup_schedule(file_path, schedule_type, schedule_time, schedule_day,
                   test_name, site, api_url, evaluate_api_url,
                   custom_interval=None, custom_unit=None):
    logger.info(f"Thi·∫øt l·∫≠p l·ªãch cho test: {test_name} - {schedule_type} - Site: {site}")
    
    import schedule  # ƒë·∫£m b·∫£o import trong h√†m ho·∫∑c ƒë·∫ßu file
    
    # Lo·∫°i b·ªè vi·ªác d√πng job = schedule.every() r·ªìi ti·∫øp t·ª•c job.xxx
    # Thay v√†o ƒë√≥ m·ªói nh√°nh s·∫Ω t·∫°o schedule m·ªõi tr·ª±c ti·∫øp
    
    if schedule_type == "minute":
        # ch·∫°y m·ªói ph√∫t
        schedule.every().minute.do(
            run_scheduled_test,
            file_path, test_name, site, api_url, evaluate_api_url
        )
    
    elif schedule_type == "hourly":
        # ch·∫°y m·ªói gi·ªù t·∫°i ph√∫t c·ª• th·ªÉ
        # schedule.every().hour.at(":MM").do(...)
        minute = schedule_time.split(':')[1]
        schedule.every().hour.at(f":{minute}").do(
            run_scheduled_test,
            file_path, test_name, site, api_url, evaluate_api_url
        )
    
    elif schedule_type == "daily":
        # m·ªói ng√†y v√†o l√∫c HH:MM
        schedule.every().day.at(schedule_time).do(
            run_scheduled_test,
            file_path, test_name, site, api_url, evaluate_api_url
        )
    
    elif schedule_type == "weekly":
        day = schedule_day.lower()
        if day == "monday":
            schedule.every().monday.at(schedule_time).do(
                run_scheduled_test,
                file_path, test_name, site, api_url, evaluate_api_url
            )
        elif day == "tuesday":
            schedule.every().tuesday.at(schedule_time).do(
                run_scheduled_test,
                file_path, test_name, site, api_url, evaluate_api_url
            )
        elif day == "wednesday":
            schedule.every().wednesday.at(schedule_time).do(
                run_scheduled_test,
                file_path, test_name, site, api_url, evaluate_api_url
            )
        elif day == "thursday":
            schedule.every().thursday.at(schedule_time).do(
                run_scheduled_test,
                file_path, test_name, site, api_url, evaluate_api_url
            )
        elif day == "friday":
            schedule.every().friday.at(schedule_time).do(
                run_scheduled_test,
                file_path, test_name, site, api_url, evaluate_api_url
            )
        elif day == "saturday":
            schedule.every().saturday.at(schedule_time).do(
                run_scheduled_test,
                file_path, test_name, site, api_url, evaluate_api_url
            )
        elif day == "sunday":
            schedule.every().sunday.at(schedule_time).do(
                run_scheduled_test,
                file_path, test_name, site, api_url, evaluate_api_url
            )
        else:
            # m·∫∑c ƒë·ªãnh Monday n·∫øu kh√¥ng h·ª£p l·ªá
            schedule.every().monday.at(schedule_time).do(
                run_scheduled_test,
                file_path, test_name, site, api_url, evaluate_api_url
            )
    
    elif schedule_type == "custom" and custom_interval and custom_unit:
        # ch·∫°y theo kho·∫£ng custom
        if custom_unit == "ph√∫t":
            schedule.every(custom_interval).minutes.do(
                run_scheduled_test,
                file_path, test_name, site, api_url, evaluate_api_url
            )
        elif custom_unit == "gi·ªù":
            schedule.every(custom_interval).hours.do(
                run_scheduled_test,
                file_path, test_name, site, api_url, evaluate_api_url
            )
        elif custom_unit == "ng√†y":
            schedule.every(custom_interval).days.do(
                run_scheduled_test,
                file_path, test_name, site, api_url, evaluate_api_url
            )
        elif custom_unit == "tu·∫ßn":
            schedule.every(custom_interval).weeks.do(
                run_scheduled_test,
                file_path, test_name, site, api_url, evaluate_api_url
            )
        else:
            logger.warning(f"ƒê∆°n v·ªã l·ªãch kh√¥ng h·ª£p l·ªá: {custom_unit}")
    else:
        logger.warning(f"Kh√¥ng c√≥ l·ªãch h·ª£p l·ªá cho lo·∫°i {schedule_type}")
    
    # Kh·ªüi ƒë·ªông thread n·∫øu ch∆∞a c√≥ cho site
    if site not in st.session_state.schedule_thread or not st.session_state.schedule_thread[site].is_alive():
        thread = threading.Thread(target=schedule_manager, daemon=True)
        st.session_state.schedule_thread[site] = thread
        thread.start()
        logger.info(f"ƒê√£ kh·ªüi ƒë·ªông thread qu·∫£n l√Ω l·ªãch cho site: {site}")

# Giao di·ªán Streamlit
st.title("ü§ñ Agent Testing")

# --- C·∫•u h√¨nh v√† c√°c bi·∫øn to√†n c·ª•c ---
with st.expander("‚öôÔ∏è C·∫•u h√¨nh API v√† c√°c tham s·ªë", expanded=False):
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**C·∫•u h√¨nh API**")
        API_URL = st.text_input("API URL", st.session_state.get("api_url", "https://site1.com"))
        EVALUATE_API_URL = st.text_input("Evaluate API URL", st.session_state.get("evaluate_api_url", "https://site2.com"))
    
    with col2:
        st.write("**C·∫•u h√¨nh Test**")
        MAX_WORKERS = st.slider("S·ªë lu·ªìng x·ª≠ l√Ω ƒë·ªìng th·ªùi", 1, 20, 5)
        add_chat_history_global = st.checkbox("Th√™m chat history (gi·∫£ l·∫≠p ƒë√£ cung c·∫•p th√¥ng tin)", value=False)
    
    st.divider()
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.write("**Ti√™u ch√≠ ƒë√°nh gi√° fail**")
        fail_criterion = st.selectbox(
            "Ch·ªçn ti√™u ch√≠",
            ["accuracy", "relevance", "completeness", "clarity", "tone", "average"],
            index=0,
            help="Ti√™u ch√≠ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ x√°c ƒë·ªãnh test case fail"
        )
    
    with col2:
        st.write("**Ng∆∞·ª°ng fail**")
        fail_threshold = st.number_input(
            "Ng∆∞·ª°ng ƒëi·ªÉm (< ng∆∞·ª°ng = fail)",
            min_value=0.0,
            max_value=10.0,
            value=8.0,
            step=0.5,
            help="Test case c√≥ ƒëi·ªÉm th·∫•p h∆°n ng∆∞·ª°ng n√†y s·∫Ω ƒë∆∞·ª£c ƒë√°nh d·∫•u fail"
        )
    
    with col3:
        st.write("**T√≥m t·∫Øt c·∫•u h√¨nh**")
        st.info(f"Fail n·∫øu **{fail_criterion}** < {fail_threshold}")
    
    st.session_state.api_url = API_URL
    st.session_state.evaluate_api_url = EVALUATE_API_URL
    st.session_state.fail_criterion = fail_criterion
    st.session_state.fail_threshold = fail_threshold

# --- Prompt Management Functions ---
def get_prompt_paths(site):
    """Get prompt file paths for a specific site"""
    prompt_dir = os.path.join("prompts", site)
    return {
        "system_prompt": os.path.join(prompt_dir, "system_prompt.txt"),
        "human_prompt": os.path.join(prompt_dir, "human_prompt.txt")
    }

def get_extract_sections_path(site):
    """Get extract_sections.py file path for a specific site"""
    utils_dir = os.path.join("utils", site)
    return os.path.join(utils_dir, "extract_sections.py")

def load_prompts_for_site(site):
    """Load prompts for a specific site"""
    prompt_paths = get_prompt_paths(site)
    prompts = {}
    
    try:
        if os.path.exists(prompt_paths["system_prompt"]):
            with open(prompt_paths["system_prompt"], "r", encoding="utf-8") as f:
                prompts["system_prompt"] = f.read()
        else:
            prompts["system_prompt"] = ""
            
        if os.path.exists(prompt_paths["human_prompt"]):
            with open(prompt_paths["human_prompt"], "r", encoding="utf-8") as f:
                prompts["human_prompt"] = f.read()
        else:
            prompts["human_prompt"] = ""
            
    except Exception as e:
        logger.error(f"L·ªói khi ƒë·ªçc prompts cho site {site}: {str(e)}")
        prompts = {"system_prompt": "", "human_prompt": ""}
    
    return prompts

def save_prompts_for_site(site, system_prompt, human_prompt):
    """Save prompts for a specific site"""
    prompt_paths = get_prompt_paths(site)
    
    try:
        # Create directory if not exists
        os.makedirs(os.path.dirname(prompt_paths["system_prompt"]), exist_ok=True)
        
        # Save system prompt
        with open(prompt_paths["system_prompt"], "w", encoding="utf-8") as f:
            f.write(system_prompt)
            
        # Save human prompt
        with open(prompt_paths["human_prompt"], "w", encoding="utf-8") as f:
            f.write(human_prompt)
            
        logger.info(f"ƒê√£ l∆∞u prompts cho site {site}")
        return True
        
    except Exception as e:
        logger.error(f"L·ªói khi l∆∞u prompts cho site {site}: {str(e)}")
        return False

def load_extract_sections_for_site(site):
    """Load extract_sections.py for a specific site"""
    extract_path = get_extract_sections_path(site)
    
    try:
        if os.path.exists(extract_path):
            with open(extract_path, "r", encoding="utf-8") as f:
                return f.read()
        else:
            return ""
    except Exception as e:
        logger.error(f"L·ªói khi ƒë·ªçc extract_sections cho site {site}: {str(e)}")
        return ""

def save_extract_sections_for_site(site, extract_code):
    """Save extract_sections.py for a specific site"""
    extract_path = get_extract_sections_path(site)
    
    try:
        # Create directory if not exists
        os.makedirs(os.path.dirname(extract_path), exist_ok=True)
        
        with open(extract_path, "w", encoding="utf-8") as f:
            f.write(extract_code)
            
        logger.info(f"ƒê√£ l∆∞u extract_sections cho site {site}")
        return True
        
    except Exception as e:
        logger.error(f"L·ªói khi l∆∞u extract_sections cho site {site}: {str(e)}")
        return False

def get_default_extract_sections_template(site):
    """Get default extract_sections template based on site"""
    if site == "THFC":
        return '''import requests
import re
from datetime import datetime
import json
import json_repair

def query(API_URL, payload):
    response = requests.post(API_URL, json=payload)
    return response

def extract_json(response_text):
    pattern = r"```json\\s*([\\[{].*?[\\]}])\\s*```"
    match = re.search(pattern, response_text, re.DOTALL)
    if match:
        try:
            obj = json.loads(match.group(1))
        except:
            obj = json_repair.loads(match.group(1))
        return obj
    else:
        obj = json_repair.loads(response_text)
        return obj
    return None

def extract_section(text):
    json_data = extract_json(text)
    print(f"JSON data:\\n{json_data}")
    results = {}
    if json_data:
        results["scores"] = {}
        relevance = json_data["relevance"]
        accuracy = json_data["accuracy"]
        completeness = json_data["completeness"]
        access_control = json_data["access_control"]
        clarity = json_data["clarity"]
        results["scores"]["relevance"] = relevance
        results["scores"]["accuracy"] = accuracy
        results["scores"]["completeness"] = completeness
        results["scores"]["access_control"] = access_control
        results["scores"]["clarity"] = clarity
        results["scores"]["average"] = (relevance + accuracy + completeness + access_control + clarity) / 5
        results["comments"] = json_data["comments"]
        print(f"Extracted: {results}")
        return results
    else:
        return None'''
    else:  # Agent HR N·ªôi b·ªô
        return '''import requests
import re
from datetime import datetime
import json
import json_repair

def query(API_URL, payload):
    response = requests.post(API_URL, json=payload)
    return response

def extract_json(response_text):
    pattern = r"```json\\s*([\\[{].*?[\\]}])\\s*```"
    match = re.search(pattern, response_text, re.DOTALL)
    if match:
        try:
            obj = json.loads(match.group(1))
        except:
            obj = json_repair.loads(match.group(1))
        return obj
    else:
        obj = json_repair.loads(response_text)
        return obj
    return None

def extract_section(text):
    json_data = extract_json(text)
    print(f"JSON data:\\n{json_data}")
    results = {}
    if json_data:
        results["scores"] = {}
        relevance = json_data["relevance"]
        accuracy = json_data["accuracy"]
        completeness = json_data["completeness"]
        clarity = json_data["clarity"]
        tone = json_data["tone"]
        results["scores"]["relevance"] = relevance
        results["scores"]["accuracy"] = accuracy
        results["scores"]["completeness"] = completeness
        results["scores"]["clarity"] = clarity
        results["scores"]["tone"] = tone
        results["scores"]["average"] = (relevance + accuracy + completeness + clarity + tone) / 5
        results["comments"] = json_data["comments"]
        return results
    else:
        return None'''

def auto_generate_extract_sections_from_prompt(system_prompt):
    """T·ª± ƒë·ªông t·∫°o extract sections code d·ª±a tr√™n system prompt"""
    import re
    
    # T√¨m c√°c ti√™u ch√≠ ƒë√°nh gi√° trong system prompt - C√≥ b·∫Øt c·∫£ m√¥ t·∫£ trong ngo·∫∑c
    criteria = []
    criteria_descriptions = []
    lines = system_prompt.split('\n')
    
    for line in lines:
        line = line.strip()
        # T√¨m pattern ### s·ªë. T√™n ti√™u ch√≠ (M√¥ t·∫£)
        match = re.match(r'^###\s*\d+\.\s*([^(]+?)\s*\(([^)]+)\)\s*$', line, re.IGNORECASE)
        if match:
            criterion = match.group(1).strip()
            description = match.group(2).strip()
            if criterion and len(criterion) < 50:  # Ch·ªâ l·∫•y t√™n ng·∫Øn
                criteria.append(criterion)
                criteria_descriptions.append(description)
        else:
            # Th·ª≠ pattern kh√¥ng c√≥ m√¥ t·∫£
            match = re.match(r'^###\s*\d+\.\s*([^(]+?)\s*$', line, re.IGNORECASE)
            if match:
                criterion = match.group(1).strip()
                if criterion and len(criterion) < 50:
                    criteria.append(criterion)
                    criteria_descriptions.append("")
    
    # N·∫øu kh√¥ng t√¨m th·∫•y, th·ª≠ t√¨m v·ªõi format kh√°c (d·∫•u -)
    if not criteria:
        for line in lines:
            line = line.strip()
            # T√¨m pattern - T√™n ti√™u ch√≠ (M√¥ t·∫£)
            match = re.match(r'^-\s*([^(]+?)\s*\(([^)]+)\)\s*$', line, re.IGNORECASE)
            if match:
                criterion = match.group(1).strip()
                description = match.group(2).strip()
                if criterion and len(criterion) < 50:
                    criteria.append(criterion)
                    criteria_descriptions.append(description)
            else:
                # Th·ª≠ pattern kh√¥ng c√≥ m√¥ t·∫£
                match = re.match(r'^-\s*([^(]+?)\s*$', line, re.IGNORECASE)
                if match:
                    criterion = match.group(1).strip()
                    if criterion and len(criterion) < 50:
                        criteria.append(criterion)
                        criteria_descriptions.append("")
    
    # Chu·∫©n h√≥a t√™n criteria th√†nh lowercase v√† thay kho·∫£ng tr·∫Øng b·∫±ng _
    normalized_criteria = []
    for criterion in criteria:
        # Lo·∫°i b·ªè s·ªë th·ª© t·ª± v√† k√Ω t·ª± ƒë·∫∑c bi·ªát
        clean_name = re.sub(r'^\d+\.?\s*', '', criterion)
        clean_name = re.sub(r'[^\w\s]', '', clean_name)
        clean_name = clean_name.strip().lower().replace(' ', '_')
        normalized_criteria.append(clean_name)
    
    # Lo·∫°i b·ªè duplicate v√† gi·ªØ th·ª© t·ª±, ƒë·ªìng th·ªùi gi·ªØ c·∫£ description
    seen = set()
    unique_criteria = []
    unique_descriptions = []
    for i, criterion in enumerate(normalized_criteria):
        if criterion not in seen:
            seen.add(criterion)
            unique_criteria.append(criterion)
            unique_descriptions.append(criteria_descriptions[i] if i < len(criteria_descriptions) else "")
    
    # T·∫°o code extract sections
    code_lines = [
        'import requests',
        'import re',
        'from datetime import datetime',
        'import json',
        'import json_repair',
        '',
        'def query(API_URL, payload):',
        '    response = requests.post(API_URL, json=payload)',
        '    return response',
        '',
        'def extract_json(response_text):',
        '    pattern = r"```json\\\\s*([\\\\[{].*?[\\\\]}])\\\\s*```"',
        '    match = re.search(pattern, response_text, re.DOTALL)',
        '    if match:',
        '        try:',
        '            obj = json.loads(match.group(1))',
        '        except:',
        '            obj = json_repair.loads(match.group(1))',
        '        return obj',
        '    else:',
        '        obj = json_repair.loads(response_text)',
        '        return obj',
        '    return None',
        '',
        'def extract_section(text):',
        '    json_data = extract_json(text)',
        '    print(f"JSON data:\\\\n{json_data}")',
        '    results = {}',
        '    if json_data:',
        '        results["scores"] = {}',
    ]
    
    # Th√™m c√°c d√≤ng extract cho t·ª´ng criteria
    for criterion in unique_criteria:
        code_lines.append(f'        {criterion} = json_data["{criterion}"]')
        code_lines.append(f'        results["scores"]["{criterion}"] = {criterion}')
    
    # T√≠nh average
    criteria_list = ', '.join(unique_criteria)
    code_lines.extend([
        f'        results["scores"]["average"] = ({criteria_list}) / {len(unique_criteria)}',
        '        results["comments"] = json_data["comments"]',
        '        print(f"Extracted: {results}")',
        '        return results',
        '    else:',
        '        return None'
    ])
    
    # Return c·∫£ code v√† mapping info ƒë·ªÉ hi·ªÉn th·ªã
    return {
        'code': '\\n'.join(code_lines),
        'criteria': criteria,
        'normalized_criteria': unique_criteria,
        'descriptions': unique_descriptions
    }


# T·∫£i prompts
def load_prompts():
    global evaluate_system_prompt
    try:
        site = get_current_site()
        prompts = load_prompts_for_site(site)
        evaluate_system_prompt = prompts["system_prompt"]
    except FileNotFoundError:
        st.error("Kh√¥ng t√¨m th·∫•y file prompt. Vui l√≤ng ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n.")
        evaluate_system_prompt = ""
load_prompts()

# --- C√°c h√†m x·ª≠ l√Ω ch√≠nh ---
progress_queue = st.empty()

def update_progress(container, total):
    processed_count = 0
    while processed_count < total:
        try:
            message = progress_queue.get(timeout=1)
            if "SUCCESS" in message:
                processed_count += 1
            container.text(f"Ti·∫øn tr√¨nh: {processed_count}/{total} c√¢u h·ªèi ƒë√£ x·ª≠ l√Ω.")
            st.info(message)
        except Exception:
            break

def extract_section(text):
    try:
        # Ki·ªÉm tra xem text c√≥ ch·ª©a c√°c keyword c·∫ßn thi·∫øt kh√¥ng
        if "scores:" not in text or "comments:" not in text:
            return {"scores": {}, "comments": "Format ƒë√°nh gi√° kh√¥ng h·ª£p l·ªá - thi·∫øu scores ho·∫∑c comments"}
        
        # T√¨m v√† tr√≠ch xu·∫•t ƒëi·ªÉm
        scores_parts = text.split("scores:")
        if len(scores_parts) < 2:
            return {"scores": {}, "comments": "Kh√¥ng t√¨m th·∫•y ph·∫ßn scores"}
        
        scores_section = scores_parts[1]
        comments_parts = scores_section.split("comments:")
        if len(comments_parts) < 2:
            return {"scores": {}, "comments": "Kh√¥ng t√¨m th·∫•y ph·∫ßn comments"}
        
        scores_str = comments_parts[0].strip()
        comments = comments_parts[1].strip()
        
        # Ki·ªÉm tra scores_str c√≥ r·ªóng kh√¥ng
        if not scores_str:
            return {"scores": {}, "comments": "Ph·∫ßn scores r·ªóng"}
        
        # Th·ª≠ parse scores
        try:
            scores = eval(scores_str)
            if not isinstance(scores, dict):
                scores = {}
        except Exception as parse_error:
            logger.warning(f"L·ªói khi parse scores: {parse_error}")
            scores = {}
        
        return {"scores": scores, "comments": comments}
    except Exception as e:
        logger.error(f"L·ªói khi tr√≠ch xu·∫•t: {e}")
        return {"scores": {}, "comments": f"L·ªói khi ph√¢n t√≠ch k·∫øt qu·∫£ ƒë√°nh gi√°: {str(e)}"}

def process_single_question(question, true_answer, index, total_questions, add_chat_history=False, custom_history=None, site=None, api_url=None, evaluate_api_url=None):
    try:
        chat_id = str(uuid4())
        payload = {
            "chat_id": chat_id,
            "question": question,
            "site": site or get_current_site()
        }
        if add_chat_history and custom_history:
            payload["chat_history"] = custom_history

        request_api_url = api_url or API_URL
        request_evaluate_api_url = evaluate_api_url or EVALUATE_API_URL

        response = requests.post(request_api_url, json=payload)
        if not response.ok:
            return f"L·ªói API: {response.text}"
        
        site_response = response.json()["text"]
        
        # Load human prompt for current site
        site_prompts = load_prompts_for_site(site or get_current_site())
        human_prompt_template = site_prompts["human_prompt"]
        
        # Format human prompt with actual values
        evaluate_human_prompt = human_prompt_template.format(
            question=question,
            true_answer=true_answer,
            agent_answer=site_response
        )
        
        evaluate_payload = {
            "question": "ƒê√°nh gi√° c√¢u tr·∫£ l·ªùi t·ª´ agent so v·ªõi c√¢u tr·∫£ l·ªùi chu·∫©n (true_answer)",
            "overrideConfig": {
                "systemMessagePrompt": evaluate_system_prompt,
                "humanMessagePrompt": evaluate_human_prompt
            }
        }
        evaluate_response = requests.post(request_evaluate_api_url, json=evaluate_payload)
        
        if not evaluate_response.ok:
            return f"L·ªói khi ƒë√°nh gi√° c√¢u tr·∫£ l·ªùi: {evaluate_response.text}"
        
        time.sleep(5)
        
        try:
            evaluate_json = evaluate_response.json()
            if "text" not in evaluate_json:
                return f"Response ƒë√°nh gi√° kh√¥ng c√≥ tr∆∞·ªùng 'text': {evaluate_json}"
            
            evaluate_response_text = evaluate_json["text"]
            if not evaluate_response_text:
                return "Response ƒë√°nh gi√° r·ªóng"
                
            # Import site-specific extract_section function
            import sys
            import importlib.util
            
            site = site or get_current_site()
            extract_path = get_extract_sections_path(site)
            
            if os.path.exists(extract_path):
                spec = importlib.util.spec_from_file_location("extract_sections", extract_path)
                extract_module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(extract_module)
                evaluate_result = extract_module.extract_section(evaluate_response_text)
            else:
                # Fallback to default extract_section
                evaluate_result = extract_section(evaluate_response_text)
                
            # ƒê·∫£m b·∫£o evaluate_result kh√¥ng ph·∫£i None
            if evaluate_result is None:
                evaluate_result = {"scores": {}, "comments": "L·ªói: Kh√¥ng th·ªÉ tr√≠ch xu·∫•t k·∫øt qu·∫£ ƒë√°nh gi√°"}
        except Exception as e:
            return f"L·ªói khi x·ª≠ l√Ω response ƒë√°nh gi√°: {str(e)}"

        return {
            "chat_id": chat_id,
            "question": question,
            "true_answer": true_answer,
            "site_response": site_response,
            "evaluate_result": evaluate_result,
        }
    except requests.exceptions.RequestException as e:
        return f"L·ªói API: {str(e)}"
    except Exception as e:
        return f"L·ªói khi x·ª≠ l√Ω c√¢u h·ªèi {index + 1}: {str(e)}"

def process_questions_batch(questions, true_answers, add_chat_history=False, custom_history=None, test_name=None, is_scheduled=False, site=None, api_url=None, evaluate_api_url=None):
    results = []
    failed_questions = []
    
    progress_container = st.empty() if not is_scheduled else None
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(process_single_question, q, ta, i, len(questions), add_chat_history, custom_history, site, api_url, evaluate_api_url): (q, ta) for i, (q, ta) in enumerate(zip(questions, true_answers))}
        
        for i, future in enumerate(concurrent.futures.as_completed(futures)):
            question, true_answer = futures[future]
            try:
                result = future.result()
                if isinstance(result, dict):
                    # Ki·ªÉm tra evaluate_result c√≥ t·ªìn t·∫°i v√† kh√¥ng ph·∫£i None
                    if (result.get("evaluate_result") and 
                        isinstance(result["evaluate_result"], dict) and 
                        result["evaluate_result"].get("scores") and
                        isinstance(result["evaluate_result"]["scores"], dict)):
                        
                        # Ki·ªÉm tra ti√™u ch√≠ fail
                        fail_criterion = st.session_state.get("fail_criterion", "accuracy")
                        fail_threshold = st.session_state.get("fail_threshold", 8.0)
                        criterion_score = result["evaluate_result"]["scores"].get(fail_criterion, 0)
                        
                        if criterion_score < fail_threshold:
                            result["failed_details"] = {
                                "timestamp": datetime.datetime.now().isoformat(),
                                "test_name": test_name,
                                "reason": f"{fail_criterion} th·∫•p (< {fail_threshold})",
                                "expected_output": result["true_answer"],
                                "actual_output": result["site_response"],
                                "scores": result["evaluate_result"]["scores"],
                                f"{fail_criterion}_score": criterion_score
                            }
                            failed_questions.append((question, f"{fail_criterion} th·∫•p", result))
                        results.append(result)
                    else:
                        # evaluate_result kh√¥ng h·ª£p l·ªá ho·∫∑c None
                        error_result = {
                            "chat_id": str(uuid4()), "question": question, "true_answer": true_answer,
                            "site_response": result.get("site_response", "[L·ªói khi x·ª≠ l√Ω]"),
                            "evaluate_result": {"scores": {}, "comments": "L·ªói: evaluate_result kh√¥ng h·ª£p l·ªá"},
                            "failed_details": {"timestamp": datetime.datetime.now().isoformat(), "test_name": test_name, "reason": "L·ªói evaluate_result", "error_message": "evaluate_result is None or invalid"}
                        }
                        results.append(error_result)
                        failed_questions.append((question, "L·ªói evaluate_result", "evaluate_result is None or invalid"))
                else:
                    error_result = {
                        "chat_id": str(uuid4()), "question": question, "true_answer": true_answer,
                        "site_response": "[L·ªói khi x·ª≠ l√Ω]",
                        "evaluate_result": {"scores": {}, "comments": f"L·ªói: {result}"},
                        "failed_details": {"timestamp": datetime.datetime.now().isoformat("%Y-%m-%d %H:%M:%S"), "test_name": test_name, "reason": "L·ªói x·ª≠ l√Ω API", "error_message": str(result)}
                    }
                    results.append(error_result)
                    failed_questions.append((question, "L·ªói x·ª≠ l√Ω API", result))
            except Exception as e:
                error_message = f"L·ªói: {str(e)}"
                error_result = {
                    "chat_id": str(uuid4()), "question": question, "true_answer": true_answer,
                    "site_response": "[L·ªói khi x·ª≠ l√Ω]",
                    "evaluate_result": {"scores": {}, "comments": error_message},
                    "failed_details": {"timestamp": datetime.datetime.now().isoformat("%Y-%m-%d %H:%M:%S"), "test_name": test_name, "reason": "Exception", "error_message": str(e)}
                }
                results.append(error_result)
                failed_questions.append((question, "Exception", str(e)))
            
            if not is_scheduled and progress_container:
                progress_container.text(f"ƒê√£ x·ª≠ l√Ω {i + 1}/{len(questions)} c√¢u h·ªèi.")

    if failed_questions and (is_scheduled or test_name):
        failed_results = [r for r in results if "failed_details" in r]
        if failed_results:
            save_failed_test_details(failed_results, site)
    
    return results, failed_questions


# T·∫£i l·ªãch s·ª≠ test, test case th·∫•t b·∫°i v√† l·ªãch s·ª≠ thay ƒë·ªïi
def get_site_paths(site):
    site_dir = os.path.join(RESULTS_DIR, site)
    os.makedirs(site_dir, exist_ok=True)
    return {
        "failed_tests": os.path.join(site_dir, "failed_tests.pkl"),
        "test_history": os.path.join(site_dir, "test_history.pkl"),
        "test_changes": os.path.join(site_dir, "test_changes.pkl")
    }

current_site = get_current_site()
site_paths = get_site_paths(current_site)
FAILED_TESTS_FILE = site_paths["failed_tests"]
TEST_HISTORY_FILE = site_paths["test_history"]
TEST_CHANGES_FILE = site_paths["test_changes"]

if os.path.exists(TEST_HISTORY_FILE):
    with open(TEST_HISTORY_FILE, "rb") as f:
        st.session_state.test_history[current_site] = pickle.load(f)
else:
    st.session_state.test_history[current_site] = []

if os.path.exists(FAILED_TESTS_FILE):
    with open(FAILED_TESTS_FILE, "rb") as f:
        st.session_state.failed_tests[current_site] = pickle.load(f)
else:
    st.session_state.failed_tests[current_site] = []

if os.path.exists(TEST_CHANGES_FILE):
    with open(TEST_CHANGES_FILE, "rb") as f:
        st.session_state.test_changes_history[current_site] = pickle.load(f)
else:
    st.session_state.test_changes_history[current_site] = []


SCHEDULED_TESTS_DIR = "scheduled_tests"
SCHEDULED_JOBS_FILE = os.path.join(SCHEDULED_TESTS_DIR, "scheduled_jobs.pkl")
os.makedirs(SCHEDULED_TESTS_DIR, exist_ok=True)

# Functions to save and load scheduled jobs
def save_scheduled_jobs():
    """Save scheduled jobs to file"""
    try:
        with open(SCHEDULED_JOBS_FILE, "wb") as f:
            pickle.dump(st.session_state.scheduled_jobs, f)
    except Exception as e:
        logger.error(f"L·ªói khi l∆∞u scheduled jobs: {str(e)}")

def load_scheduled_jobs():
    """Load scheduled jobs from file"""
    try:
        if os.path.exists(SCHEDULED_JOBS_FILE):
            with open(SCHEDULED_JOBS_FILE, "rb") as f:
                return pickle.load(f)
        return []
    except Exception as e:
        logger.error(f"L·ªói khi t·∫£i scheduled jobs: {str(e)}")
        return []

def get_scheduled_job_for_site(site):
    """Get scheduled job for a specific site"""
    for job in st.session_state.scheduled_jobs:
        if job.get('site') == site:
            return job
    return None

def remove_scheduled_job_for_site(site):
    """Remove scheduled job for a specific site"""
    st.session_state.scheduled_jobs = [job for job in st.session_state.scheduled_jobs if job.get('site') != site]
    save_scheduled_jobs()

# Initialize scheduled jobs
if 'scheduled_jobs' not in st.session_state:
    st.session_state.scheduled_jobs = load_scheduled_jobs()

# Initialize schedule_initialized flag
if 'schedule_initialized' not in st.session_state:
    st.session_state.schedule_initialized = False

# Only setup schedule once when app starts, not on every rerun
# This prevents schedule from being reset every time user interacts with the page
if not st.session_state.schedule_initialized:
    schedule.clear()
    for job_config in st.session_state.scheduled_jobs:
        if os.path.exists(job_config["file_path"]):
            setup_schedule(
                file_path=job_config["file_path"],
                schedule_type=job_config["schedule_type"],
                schedule_time=job_config["schedule_time"],
                schedule_day=job_config["schedule_day"],
                test_name=job_config["test_name"],
                site=job_config["site"],
                api_url=job_config.get("api_url", st.session_state.get("schedule_api_url", "https://site1.com")),
                evaluate_api_url=job_config.get("evaluate_api_url", st.session_state.get("schedule_evaluate_api_url", "https://site2.com")),
                custom_interval=job_config.get("custom_interval"),
                custom_unit=job_config.get("custom_unit")
            )
        else:
            # If file is missing, mark the job for removal
            st.session_state.scheduled_jobs = [j for j in st.session_state.scheduled_jobs if j['job_id'] != job_config['job_id']]
            save_scheduled_jobs()  # Save updated list to file
    
    st.session_state.schedule_initialized = True

# Giao di·ªán Streamlit
st.title("ü§ñ Agent Testing")

# T·∫°o c√°c tab
tab1, tab2, tab3, tab4, tab5 = st.tabs(["Test ƒë∆°n l·∫ª", "Test h√†ng lo·∫°t", "L·∫≠p l·ªãch test", "Qu·∫£n l√Ω test", "Qu·∫£n l√Ω Prompts"])

with tab1:
    st.subheader("‚úèÔ∏è Test ƒë∆°n l·∫ª")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        question = st.text_area("üìù C√¢u h·ªèi:", height=150, placeholder="Nh·∫≠p c√¢u h·ªèi test...")
    
    with col2:
        true_answer = st.text_area("‚úÖ C√¢u tr·∫£ l·ªùi chu·∫©n:", height=150, placeholder="Nh·∫≠p c√¢u tr·∫£ l·ªùi m·∫´u...")
    
    if add_chat_history_global:
        with st.expander("üí¨ Thi·∫øt l·∫≠p chat history", expanded=False):
            if 'chat_history' not in st.session_state or st.session_state.chat_history is None:
                st.session_state.chat_history = [
                    {"role": "apiMessage", "content": "Vui l√≤ng cung c·∫•p h·ªç t√™n, s·ªë ƒëi·ªán tho·∫°i, tr∆∞·ªùng THPT v√† t·ªânh th√†nh sinh s·ªëng ƒë·ªÉ t√¥i c√≥ th·ªÉ t∆∞ v·∫•n t·ªët nh·∫•t. L∆∞u √Ω, th√¥ng tin b·∫°n cung c·∫•p c·∫ßn ƒë·∫£m b·∫£o t√≠nh ch√≠nh x√°c."},
                    {"role": "userMessage", "content": "[Cung c·∫•p th√¥ng tin]"}
                ]
            
            # S·ª≠ d·ª•ng m·ªôt list t·∫°m ƒë·ªÉ tr√°nh l·ªói khi x√≥a
            new_history = []
            for i, msg in enumerate(st.session_state.chat_history):
                cols = st.columns([2, 8, 1])
                role = cols[0].selectbox(f"Role {i+1}", ["apiMessage", "userMessage"], key=f"role_{i}", index=["apiMessage", "userMessage"].index(msg["role"]))
                content = cols[1].text_area(f"N·ªôi dung {i+1}", value=msg["content"], key=f"content_{i}")
                if not cols[2].button("üóëÔ∏è", key=f"delete_{i}", help="X√≥a message n√†y"):
                    new_history.append({"role": role, "content": content})
            st.session_state.chat_history = new_history

            if st.button("‚ûï Th√™m message"):
                st.session_state.chat_history.append({"role": "userMessage", "content": ""})
                st.rerun()

    col1, col2, col3 = st.columns([1, 1, 2])
    with col2:
        if st.button("‚ñ∂Ô∏è Ch·∫°y Test", type="primary", use_container_width=True):
            if question and true_answer:
                with st.spinner("‚è≥ ƒêang x·ª≠ l√Ω..."):
                    history = st.session_state.chat_history if (add_chat_history_global and st.session_state.chat_history) else None
                    result = process_single_question(question, true_answer, 0, 1, add_chat_history=add_chat_history_global, custom_history=history, site=get_current_site())
                
                if isinstance(result, dict):
                    st.success("‚úÖ X·ª≠ l√Ω th√†nh c√¥ng!")
                    
                    st.write("---")
                    st.subheader("üìä K·∫øt qu·∫£")
                    
                    col1, col2 = st.columns([1, 1])
                    
                    with col1:
                        st.write("**üí¨ C√¢u tr·∫£ l·ªùi t·ª´ Agent:**")
                        st.info(result["site_response"])
                    
                    with col2:
                        st.write("**üìà ƒêi·ªÉm ƒë√°nh gi√°:**")
                        scores = result["evaluate_result"]["scores"]
                        for metric, score in scores.items():
                            st.metric(metric.capitalize(), f"{score}/10")
                    
                    st.write("**üí≠ Nh·∫≠n x√©t v√† g√≥p √Ω c·∫£i thi·ªán:**")
                    st.text_area("Comments", value=result["evaluate_result"]["comments"], height=150, disabled=True)
                else:
                    st.error(f"‚ùå L·ªói: {result}")
            else:
                st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p ƒë·∫ßy ƒë·ªß c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi chu·∫©n")

with tab2:
    st.subheader("üìù Test h√†ng lo·∫°t t·ª´ file Excel")
    
    if add_chat_history_global:
        with st.expander("üí¨ Thi·∫øt l·∫≠p chat history", expanded=False):
            # T∆∞∆°ng t·ª± tab 1, hi·ªÉn th·ªã v√† cho ph√©p ch·ªânh s·ª≠a chat history
            if 'chat_history' not in st.session_state or st.session_state.chat_history is None:
                st.session_state.chat_history = [
                    {"role": "apiMessage", "content": "Vui l√≤ng cung c·∫•p h·ªç t√™n, s·ªë ƒëi·ªán tho·∫°i, tr∆∞·ªùng THPT v√† t·ªânh th√†nh sinh s·ªëng ƒë·ªÉ t√¥i c√≥ th·ªÉ t∆∞ v·∫•n t·ªët nh·∫•t. L∆∞u √Ω, th√¥ng tin b·∫°n cung c·∫•p c·∫ßn ƒë·∫£m b·∫£o t√≠nh ch√≠nh x√°c."},
                    {"role": "userMessage", "content": "[Cung c·∫•p th√¥ng tin]"}
                ]
            
            new_history = []
            for i, msg in enumerate(st.session_state.chat_history):
                cols = st.columns([2, 8, 1])
                role = cols[0].selectbox(f"Role {i+1}", ["apiMessage", "userMessage"], key=f"role_batch_{i}", index=["apiMessage", "userMessage"].index(msg["role"]))
                content = cols[1].text_area(f"N·ªôi dung {i+1}", value=msg["content"], key=f"content_batch_{i}")
                if not cols[2].button("üóëÔ∏è", key=f"delete_batch_{i}", help="X√≥a message n√†y"):
                    new_history.append({"role": role, "content": content})
            st.session_state.chat_history = new_history

            if st.button("‚ûï Th√™m message", key="add_message_batch"):
                st.session_state.chat_history.append({"role": "userMessage", "content": ""})
                st.rerun()

    col1, col2 = st.columns([3, 1])
    with col1:
        uploaded_file = st.file_uploader("üìÅ Ch·ªçn file Excel ch·ª©a test cases", type=['xlsx', 'xls'])
    
    with col2:
        st.write("")  # Spacer
        st.write("")  # Spacer
        if uploaded_file:
            st.success("‚úÖ File ƒë√£ t·∫£i l√™n")
    
    if uploaded_file is not None:
        try:
            df = pd.read_excel(uploaded_file)
            df = df.dropna(subset=[df.columns[0], df.columns[1]])
            questions = df.iloc[:, 0].tolist()
            true_answers = df.iloc[:, 1].tolist()
            
            # Kh·ªüi t·∫°o edited test cases trong session state n·∫øu ch∆∞a c√≥
            if 'test_cases_df' not in st.session_state or st.session_state.get('current_file') != uploaded_file.name:
                st.session_state.test_cases_df = pd.DataFrame({
                    'Ch·ªçn': [True] * len(questions),  # Checkbox column
                    'C√¢u h·ªèi': questions, 
                    'C√¢u tr·∫£ l·ªùi chu·∫©n': true_answers
                })
                st.session_state.current_file = uploaded_file.name
            
            st.write("### üìã Danh s√°ch test cases (c√≥ th·ªÉ ch·ªânh s·ª≠a)")
            st.info("üí° Tip: B·∫°n c√≥ th·ªÉ click v√†o √¥ ƒë·ªÉ ch·ªânh s·ª≠a tr·ª±c ti·∫øp c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi. Tick ‚úì v√†o c·ªôt 'Ch·ªçn' ƒë·ªÉ ch·ªçn test case mu·ªën ch·∫°y.")
            
            # S·ª≠ d·ª•ng st.data_editor ƒë·ªÉ c√≥ th·ªÉ ch·ªânh s·ª≠a
            edited_df = st.data_editor(
                st.session_state.test_cases_df,
                use_container_width=True,
                hide_index=True,
                num_rows="dynamic",  # Cho ph√©p th√™m/x√≥a d√≤ng
                column_config={
                    "Ch·ªçn": st.column_config.CheckboxColumn(
                        "Ch·ªçn",
                        help="Tick ƒë·ªÉ ch·ªçn test case n√†y",
                        default=True,
                        width="small"
                    ),
                    "C√¢u h·ªèi": st.column_config.TextColumn(
                        "C√¢u h·ªèi",
                        help="N·ªôi dung c√¢u h·ªèi",
                        width="large",
                        required=True
                    ),
                    "C√¢u tr·∫£ l·ªùi chu·∫©n": st.column_config.TextColumn(
                        "C√¢u tr·∫£ l·ªùi chu·∫©n",
                        help="C√¢u tr·∫£ l·ªùi m·∫´u ƒë·ªÉ so s√°nh",
                        width="large",
                        required=True
                    ),
                },
                key="test_cases_editor"
            )
            
            # C·∫≠p nh·∫≠t session state v·ªõi d·ªØ li·ªáu ƒë√£ ch·ªânh s·ª≠a
            st.session_state.test_cases_df = edited_df
            
            # L·ªçc c√°c d√≤ng ƒë∆∞·ª£c ch·ªçn
            selected_df = edited_df[edited_df['Ch·ªçn'] == True]
            selected_rows = selected_df.index.tolist()
            
            col1, col2, col3 = st.columns([1, 2, 1])
            with col1:
                st.metric("üìä T·ªïng test cases", len(edited_df))
            with col2:
                st.metric("‚úÖ Test cases ƒë∆∞·ª£c ch·ªçn", len(selected_df))
            with col3:
                if st.button("‚ñ∂Ô∏è Ch·∫°y test", type="primary", use_container_width=True):
                    if len(selected_df) > 0:
                        selected_questions = selected_df['C√¢u h·ªèi'].tolist()
                        selected_true_answers = selected_df['C√¢u tr·∫£ l·ªùi chu·∫©n'].tolist()
                        
                        with st.spinner("‚è≥ ƒêang x·ª≠ l√Ω test cases..."):
                            history = st.session_state.chat_history if (add_chat_history_global and st.session_state.chat_history) else None
                            results, failed_questions = process_questions_batch(
                                selected_questions, 
                                selected_true_answers, 
                                add_chat_history=add_chat_history_global, 
                                custom_history=history, 
                                test_name=uploaded_file.name, 
                                site=get_current_site()
                            )
                        
                        st.session_state.results = results
                        
                        data = {
                            'Question': [r["question"] for r in results],
                            'True Answer': [r["true_answer"] for r in results],
                            'Agent Answer': [r["site_response"] for r in results],
                            'Session ID': [r["chat_id"] for r in results],
                            'Relevance Score': [r["evaluate_result"]["scores"].get("relevance", 0) for r in results],
                            'Accuracy Score': [r["evaluate_result"]["scores"].get("accuracy", 0) for r in results],
                            'Completeness Score': [r["evaluate_result"]["scores"].get("completeness", 0) for r in results],
                            'Clarity Score': [r["evaluate_result"]["scores"].get("clarity", 0) for r in results],
                            'Tone Score': [r["evaluate_result"]["scores"].get("tone", 0) for r in results],
                            'Average Score': [r["evaluate_result"]["scores"].get("average", 0) for r in results],
                            'Comment': [r["evaluate_result"].get("comments", "") for r in results]
                        }
                        results_df = pd.DataFrame(data)
                        st.session_state.results_df = results_df
                        
                        st.write("---")
                        st.subheader(f"üìä K·∫øt qu·∫£ ƒë√°nh gi√° ({len(results)} c√¢u h·ªèi)")
                        
                        # Hi·ªÉn th·ªã metrics t·ªïng quan
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("‚úÖ Passed", sum(1 for r in results if "failed_details" not in r))
                        with col2:
                            st.metric("‚ùå Failed", sum(1 for r in results if "failed_details" in r))
                        with col3:
                            avg_score = sum(r["evaluate_result"]["scores"].get("average", 0) for r in results) / len(results) if results else 0
                            st.metric("üìà ƒêi·ªÉm TB", f"{avg_score:.2f}")
                        with col4:
                            pass_rate = (sum(1 for r in results if "failed_details" not in r) / len(results) * 100) if results else 0
                            st.metric("üìä T·ª∑ l·ªá pass", f"{pass_rate:.1f}%")
                        
                        st.dataframe(results_df, use_container_width=True, hide_index=True)
                        
                        col1, col2 = st.columns([1, 1])
                        with col1:
                            st.download_button(
                                label="üì• T·∫£i xu·ªëng k·∫øt qu·∫£ (CSV)", 
                                data=results_df.to_csv(index=False).encode('utf-8'), 
                                file_name=f'evaluation_results_{uploaded_file.name}.csv', 
                                mime='text/csv',
                                use_container_width=True
                            )
                        with col2:
                            if failed_questions:
                                st.warning(f"‚ö†Ô∏è C√≥ {len(failed_questions)} c√¢u h·ªèi x·ª≠ l√Ω th·∫•t b·∫°i")
                            else:
                                st.success(f"‚úÖ ƒê√£ ho√†n th√†nh ƒë√°nh gi√° {len(results)} c√¢u h·ªèi")
                    else:
                        st.warning("‚ö†Ô∏è Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt test case ƒë·ªÉ ch·∫°y")
        except Exception as e:
            st.error(f"L·ªói khi ƒë·ªçc file Excel: {str(e)}")
    else:
        st.info("Vui l√≤ng t·∫£i l√™n file Excel ƒë·ªÉ b·∫Øt ƒë·∫ßu")

with tab3:
    st.subheader("L·∫≠p l·ªãch ch·∫°y test t·ª± ƒë·ªông")

    site = get_current_site()
    existing_job = get_scheduled_job_for_site(site)
    
    if existing_job:
        st.info(f"Site **{site}** ƒë√£ c√≥ c·∫•u h√¨nh l·ªãch test. B·∫°n c√≥ th·ªÉ ch·ªânh s·ª≠a ho·∫∑c x√≥a c·∫•u h√¨nh hi·ªán t·∫°i.")
        
        st.write("### C·∫•u h√¨nh hi·ªán t·∫°i")
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.write(f"**T√™n Test:** {existing_job['test_name']}")
            st.write(f"**Lo·∫°i l·ªãch:** {existing_job['schedule_type']}")
            st.write(f"**Th·ªùi gian:** {existing_job.get('schedule_time', 'N/A')}")
            if existing_job.get('schedule_day'):
                st.write(f"**Ng√†y:** {existing_job['schedule_day']}")
            if existing_job.get('custom_interval') and existing_job.get('custom_unit'):
                st.write(f"**T√πy ch·ªânh:** M·ªói {existing_job['custom_interval']} {existing_job['custom_unit']}")
            st.write(f"**API URL:** `{existing_job.get('api_url', 'Ch∆∞a c·∫•u h√¨nh')}`")
            st.write(f"**Evaluate API URL:** `{existing_job.get('evaluate_api_url', 'Ch∆∞a c·∫•u h√¨nh')}`")
            
            # Show next run time
            found_job = None
            for job in schedule.jobs:
                try:
                    if job.job_func.args[1] == existing_job['test_name'] and job.job_func.args[2] == existing_job['site']:
                        found_job = job
                        break
                except (IndexError, AttributeError):
                    continue
            
            if found_job:
                st.write(f"**Ch·∫°y l·∫ßn t·ªõi:** {found_job.next_run.strftime('%Y-%m-%d %H:%M:%S') if found_job.next_run else 'N/A'}")
            else:
                st.warning("Kh√¥ng th·ªÉ l·∫•y th√¥ng tin chi ti·∫øt l·ªãch ch·∫°y.")
        
        with col2:
            if st.button("Ch·ªânh s·ª≠a", key="edit_existing_job"):
                st.session_state.editing_existing_job = True
                st.rerun()
            
            if st.button("X√≥a c·∫•u h√¨nh", key="delete_existing_job"):
                # Ch·ªâ x√≥a file test (kh√¥ng ph·∫£i k·∫øt qu·∫£ test)
                if os.path.exists(existing_job['file_path']):
                    # Ki·ªÉm tra xem c√≥ ph·∫£i file test hay file k·∫øt qu·∫£
                    if 'scheduled_tests' in existing_job['file_path']:
                        # ƒê√¢y l√† file test cho scheduled job - c√≥ th·ªÉ x√≥a
                        os.remove(existing_job['file_path'])
                        st.info(f"ƒê√£ x√≥a file test: {os.path.basename(existing_job['file_path'])}")
                    else:
                        st.warning("File n√†y c√≥ th·ªÉ ch·ª©a k·∫øt qu·∫£ test quan tr·ªçng. Kh√¥ng x√≥a.")
                
                # Remove from scheduled jobs
                remove_scheduled_job_for_site(site)
                
                # Reset schedule initialization flag to recreate schedule
                st.session_state.schedule_initialized = False
                
                st.success(f"ƒê√£ x√≥a c·∫•u h√¨nh l·ªãch test cho site '{site}'. K·∫øt qu·∫£ test tr∆∞·ªõc ƒë√≥ v·∫´n ƒë∆∞·ª£c gi·ªØ l·∫°i.")
                st.rerun()
        
        # Show edit form if editing
        if st.session_state.get('editing_existing_job', False):
            st.write("### Ch·ªânh s·ª≠a c·∫•u h√¨nh")
            
            # API URLs
            new_api_url = st.text_input("API URL", value=existing_job.get('api_url', "https://site1.com"), key="edit_api_url")
            new_eval_api_url = st.text_input("Evaluate API URL", value=existing_job.get('evaluate_api_url', "https://site2.com"), key="edit_eval_api_url")
            
            # Test file
            st.write("**File test hi·ªán t·∫°i:**")
            if os.path.exists(existing_job['file_path']):
                try:
                    df_current = pd.read_excel(existing_job['file_path'])
                    st.write(f"File: `{os.path.basename(existing_job['file_path'])}` ({len(df_current)} d√≤ng)")
                    st.write("**Preview 5 d√≤ng ƒë·∫ßu ti√™n:**")
                    st.dataframe(df_current.head(5), use_container_width=True)
                except Exception as e:
                    st.error(f"L·ªói khi ƒë·ªçc file hi·ªán t·∫°i: {str(e)}")
            else:
                st.warning("File test hi·ªán t·∫°i kh√¥ng t·ªìn t·∫°i")
            
            st.write("**Upload file test m·ªõi (ƒë·ªÉ tr·ªëng n·∫øu kh√¥ng thay ƒë·ªïi):**")
            new_test_file = st.file_uploader("File test m·ªõi", type=['xlsx', 'xls'], key="edit_test_file")
            
            # Hi·ªÉn th·ªã preview file m·ªõi n·∫øu c√≥
            if new_test_file is not None:
                try:
                    df_new_preview = pd.read_excel(new_test_file)
                    st.write("**Preview 5 d√≤ng ƒë·∫ßu ti√™n c·ªßa file m·ªõi:**")
                    st.dataframe(df_new_preview.head(5), use_container_width=True)
                    
                    # Reset file pointer ƒë·ªÉ c√≥ th·ªÉ ƒë·ªçc l·∫°i sau n√†y
                    new_test_file.seek(0)
                except Exception as e:
                    st.error(f"L·ªói khi ƒë·ªçc file Excel m·ªõi: {str(e)}")
                    new_test_file = None
            
            new_test_name = st.text_input("T√™n test m·ªõi", value=existing_job['test_name'], key="edit_test_name")
            
            # Schedule settings
            current_schedule_type = existing_job.get('schedule_type', 'daily')
            if current_schedule_type is None:
                current_schedule_type = 'daily'
            schedule_type_index = ["minute", "hourly", "daily", "weekly", "custom"].index(current_schedule_type) if current_schedule_type in ["minute", "hourly", "daily", "weekly", "custom"] else 2
            new_schedule_type = st.selectbox("Lo·∫°i l·ªãch", ["minute", "hourly", "daily", "weekly", "custom"], 
                                            index=schedule_type_index, 
                                            key="edit_schedule_type")
            
            new_schedule_time = None
            new_schedule_day = None
            new_custom_interval = None
            new_custom_unit = None
            
            col1, col2 = st.columns(2)
            with col1:
                if new_schedule_type == "minute":
                    st.info("Test s·∫Ω ch·∫°y m·ªói ph√∫t")
                    
                elif new_schedule_type == "hourly":
                    # Safe parsing for hourly schedule
                    current_time = existing_job.get('schedule_time')
                    if current_time is None or current_time == '':
                        current_time = '00:00'
                    try:
                        time_parts = current_time.split(':')
                        if len(time_parts) >= 2:
                            current_minute = int(time_parts[1])
                        else:
                            current_minute = 0
                    except (ValueError, IndexError):
                        current_minute = 0
                    minute = st.number_input("Ph√∫t", 0, 59, current_minute, key="edit_schedule_minute")
                    new_schedule_time = f"00:{minute:02d}"
                    
                elif new_schedule_type == "custom":
                    # Safe parsing for custom schedule
                    current_interval = existing_job.get('custom_interval')
                    if current_interval is None:
                        current_interval = 2
                    new_custom_interval = st.number_input("M·ªói", 1, 100, current_interval, key="edit_custom_interval")
                    
                    current_custom_unit = existing_job.get('custom_unit')
                    if current_custom_unit is None or current_custom_unit not in ["ph√∫t", "gi·ªù", "ng√†y", "tu·∫ßn"]:
                        current_custom_unit = 'gi·ªù'
                    unit_index = ["ph√∫t", "gi·ªù", "ng√†y", "tu·∫ßn"].index(current_custom_unit) if current_custom_unit in ["ph√∫t", "gi·ªù", "ng√†y", "tu·∫ßn"] else 1
                    new_custom_unit = st.selectbox("ƒê∆°n v·ªã", ["ph√∫t", "gi·ªù", "ng√†y", "tu·∫ßn"], 
                                                 index=unit_index, 
                                                 key="edit_custom_unit")
                    
                else:  # daily or weekly
                    # Safe parsing for daily/weekly schedule
                    current_time = existing_job.get('schedule_time')
                    if current_time is None or current_time == '':
                        current_time = '00:00'
                    try:
                        time_parts = current_time.split(':')
                        if len(time_parts) >= 2:
                            hour = int(time_parts[0])
                            minute = int(time_parts[1])
                            time_obj = datetime.time(hour, minute)
                        else:
                            time_obj = datetime.time(0, 0)
                    except (ValueError, IndexError):
                        time_obj = datetime.time(0, 0)
                    schedule_time_input = st.time_input("Th·ªùi gian", value=time_obj, key="edit_schedule_time")
                    new_schedule_time = schedule_time_input.strftime("%H:%M")
            
            with col2:
                if new_schedule_type == "weekly":
                    current_day = existing_job.get('schedule_day')
                    if current_day is None or current_day not in ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]:
                        current_day = 'Monday'
                    day_index = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"].index(current_day)
                    new_schedule_day = st.selectbox("Ng√†y trong tu·∫ßn", ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"], 
                                                 index=day_index, 
                                                 key="edit_schedule_day")
            
            col1, col2, col3 = st.columns([1, 1, 4])
            with col1:
                if st.button("L∆∞u thay ƒë·ªïi", key="save_edit_existing"):
                    # Update job config
                    job_index = next((i for i, job in enumerate(st.session_state.scheduled_jobs) if job['job_id'] == existing_job['job_id']), None)
                    if job_index is not None:
                        # Update file if new one provided
                        if new_test_file is not None:
                            # Remove old file
                            if os.path.exists(existing_job['file_path']):
                                try:
                                    os.remove(existing_job['file_path'])
                                    st.info(f"ƒê√£ x√≥a file test c≈©: {os.path.basename(existing_job['file_path'])}")
                                except Exception as e:
                                    st.warning(f"Kh√¥ng th·ªÉ x√≥a file c≈©: {str(e)}")
                            
                            # T·∫°o th∆∞ m·ª•c cho site n·∫øu ch∆∞a c√≥
                            site_dir = os.path.join(SCHEDULED_TESTS_DIR, site)
                            os.makedirs(site_dir, exist_ok=True)
                            
                            # Save new file
                            saved_file_name = f"{new_test_name.replace(' ', '_')}_{datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.xlsx"
                            saved_file_path = os.path.join(site_dir, saved_file_name)
                            with open(saved_file_path, "wb") as f:
                                f.write(new_test_file.getbuffer())
                            
                            st.session_state.scheduled_jobs[job_index]['file_path'] = saved_file_path
                            st.info(f"ƒê√£ l∆∞u file test m·ªõi: {saved_file_name}")
                        
                        # Update other fields
                        st.session_state.scheduled_jobs[job_index]['test_name'] = new_test_name
                        st.session_state.scheduled_jobs[job_index]['schedule_type'] = new_schedule_type
                        st.session_state.scheduled_jobs[job_index]['schedule_time'] = new_schedule_time
                        st.session_state.scheduled_jobs[job_index]['schedule_day'] = new_schedule_day
                        st.session_state.scheduled_jobs[job_index]['custom_interval'] = new_custom_interval
                        st.session_state.scheduled_jobs[job_index]['custom_unit'] = new_custom_unit
                        st.session_state.scheduled_jobs[job_index]['api_url'] = new_api_url
                        st.session_state.scheduled_jobs[job_index]['evaluate_api_url'] = new_eval_api_url
                        
                        save_scheduled_jobs()
                        
                        # Reset schedule initialization flag to recreate schedule
                        st.session_state.schedule_initialized = False
                        st.session_state.editing_existing_job = False
                        
                        st.success(f"ƒê√£ c·∫≠p nh·∫≠t c·∫•u h√¨nh l·ªãch test cho site '{site}'.")
                        st.rerun()
            
            with col2:
                if st.button("H·ªßy", key="cancel_edit_existing"):
                    st.session_state.editing_existing_job = False
                    st.rerun()
    
    else:
        st.write("### T·∫°o c·∫•u h√¨nh l·ªãch test m·ªõi")
        st.write(f"Site hi·ªán t·∫°i: **{site}**")
        
        st.write("### B∆∞·ªõc 1: C·∫•u h√¨nh API URLs cho l·ªãch test")
        schedule_api_url = st.text_input("API URL cho l·ªãch test", st.session_state.get("schedule_api_url", "https://site1.com"), key="schedule_api_url_input")
        schedule_evaluate_api_url = st.text_input("Evaluate API URL cho l·ªãch test", st.session_state.get("schedule_evaluate_api_url", "https://site2.com"), key="schedule_evaluate_api_url_input")
        
        # L∆∞u v√†o session state
        st.session_state.schedule_api_url = schedule_api_url
        st.session_state.schedule_evaluate_api_url = schedule_evaluate_api_url

        st.write("### B∆∞·ªõc 2: Ch·ªçn file test v√† ƒë·∫∑t t√™n")
        test_file = st.file_uploader("Ch·ªçn file Excel ch·ª©a test cases", type=['xlsx', 'xls'], key="schedule_file_uploader")
        
        # Hi·ªÉn th·ªã preview 5 d√≤ng ƒë·∫ßu ti√™n khi upload file
        if test_file is not None:
            try:
                df_preview = pd.read_excel(test_file)
                st.write("**Preview 5 d√≤ng ƒë·∫ßu ti√™n c·ªßa file:**")
                st.dataframe(df_preview.head(5), use_container_width=True)
                
                # Reset file pointer ƒë·ªÉ c√≥ th·ªÉ ƒë·ªçc l·∫°i sau n√†y
                test_file.seek(0)
            except Exception as e:
                st.error(f"L·ªói khi ƒë·ªçc file Excel: {str(e)}")
                test_file = None
        
        test_name = st.text_input("T√™n b·ªô test (ƒë·ªÉ nh·∫≠n di·ªán trong l·ªãch s·ª≠)", key="test_name_input")

        if test_file and test_name:
            st.write("### B∆∞·ªõc 3: Thi·∫øt l·∫≠p l·ªãch ch·∫°y test")
            
            schedule_type = st.selectbox("Lo·∫°i l·ªãch", ["minute", "hourly", "daily", "weekly", "custom"], key="schedule_type_select")
            
            schedule_time = None
            schedule_day = None
            schedule_custom_interval = None
            schedule_custom_unit = None

            col1, col2 = st.columns(2)
            with col1:
                if schedule_type == "minute":
                    st.info("Test s·∫Ω ch·∫°y m·ªói ph√∫t")
                elif schedule_type == "hourly":
                    minute = st.number_input("Ph√∫t", 0, 59, 0, key="schedule_minute")
                    schedule_time = f"00:{minute:02d}"
                elif schedule_type == "custom":
                    schedule_custom_interval = st.number_input("M·ªói", 1, 100, 2, key="schedule_custom_interval")
                    schedule_custom_unit = st.selectbox("ƒê∆°n v·ªã", ["ph√∫t", "gi·ªù", "ng√†y", "tu·∫ßn"], key="schedule_custom_unit")
                else:
                    schedule_time_input = st.time_input("Th·ªùi gian", key="schedule_time_input")
                    schedule_time = schedule_time_input.strftime("%H:%M")
            
            with col2:
                if schedule_type == "weekly":
                    schedule_day = st.selectbox("Ng√†y trong tu·∫ßn", ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"], key="schedule_day_select")

            if st.button("Thi·∫øt l·∫≠p l·ªãch"):
                # T·∫°o th∆∞ m·ª•c cho site n·∫øu ch∆∞a c√≥
                site_dir = os.path.join(SCHEDULED_TESTS_DIR, site)
                os.makedirs(site_dir, exist_ok=True)
                
                saved_file_name = f"{test_name.replace(' ', '_')}_{datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')}.xlsx"
                saved_file_path = os.path.join(site_dir, saved_file_name)
                with open(saved_file_path, "wb") as f:
                    f.write(test_file.getbuffer())

                job_config = {
                    "file_path": saved_file_path,
                    "schedule_type": schedule_type,
                    "schedule_time": schedule_time,
                    "schedule_day": schedule_day,
                    "test_name": test_name,
                    "site": site,
                    "custom_interval": schedule_custom_interval,
                    "custom_unit": schedule_custom_unit,
                    "api_url": schedule_api_url,
                    "evaluate_api_url": schedule_evaluate_api_url,
                    "job_id": str(uuid4())
                }
                st.session_state.scheduled_jobs.append(job_config)
                save_scheduled_jobs()  # Save to file
                
                # Reset schedule initialization flag to recreate schedule
                st.session_state.schedule_initialized = False
                
                st.success(f"ƒê√£ thi·∫øt l·∫≠p l·ªãch ch·∫°y test '{test_name}' cho site '{site}'.")
                st.rerun()


with tab4:
    st.subheader("Qu·∫£n l√Ω test v√† c·∫≠p nh·∫≠t t·∫≠p test")
    
    site = get_current_site()
    
    # Dashboard t·ªïng quan
    st.write("### üìä Dashboard T·ªïng Quan")
    
    if site in st.session_state.test_history and st.session_state.test_history[site]:
        # T√≠nh to√°n th·ªëng k√™ t·ªïng quan
        total_tests = len(st.session_state.test_history[site])
        total_questions = sum(test.get('num_questions', 0) for test in st.session_state.test_history[site])
        total_passed = sum(test.get('num_passed', 0) for test in st.session_state.test_history[site])
        total_failed = sum(test.get('num_failed', 0) for test in st.session_state.test_history[site])
        total_api_errors = sum(test.get('num_failed_api', 0) for test in st.session_state.test_history[site])
        total_extract_errors = sum(test.get('num_failed_extract', 0) for test in st.session_state.test_history[site])
        total_accuracy_errors = sum(test.get('num_failed_accuracy', 0) for test in st.session_state.test_history[site])
        
        overall_pass_rate = (total_passed / total_questions) * 100 if total_questions > 0 else 0
        api_error_rate = (total_api_errors / total_failed) * 100 if total_failed > 0 else 0
        
        # Dashboard v·ªõi HTML/CSS ƒë·∫πp h∆°n
        st.markdown(""" 
        <style>
        .metric-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            color: white;
            text-align: center;
            margin: 5px;
        }
        .metric-card-success {
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
        }
        .metric-card-danger {
            background: linear-gradient(135deg, #ee0979 0%, #ff6a00 100%);
        }
        .metric-card-warning {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        }
        .metric-card-info {
            background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        }
        .metric-label {
            font-size: 14px;
            font-weight: 500;
            opacity: 0.9;
            margin-bottom: 5px;
        }
        .metric-value {
            font-size: 32px;
            font-weight: bold;
            margin: 10px 0;
        }
        .dashboard-grid {
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 15px;
            margin-bottom: 20px;
        }
        @media (max-width: 1200px) {
            .dashboard-grid {
                grid-template-columns: repeat(2, 1fr);
            }
        }
        @media (max-width: 600px) {
            .dashboard-grid {
                grid-template-columns: 1fr;
            }
        }
        </style>
        """, unsafe_allow_html=True)
        
        # Grid 1: Th·ªëng k√™ ch√≠nh
        st.markdown(f"""
        <div class="dashboard-grid">
            <div class="metric-card metric-card-info">
                <div class="metric-label">üìà T·ªïng s·ªë test</div>
                <div class="metric-value">{total_tests}</div>
            </div>
            <div class="metric-card metric-card-info">
                <div class="metric-label">‚ùì T·ªïng c√¢u h·ªèi</div>
                <div class="metric-value">{total_questions}</div>
            </div>
            <div class="metric-card metric-card-success">
                <div class="metric-label">‚úÖ T·ªïng passed</div>
                <div class="metric-value">{total_passed}</div>
            </div>
            <div class="metric-card metric-card-danger">
                <div class="metric-label">‚ùå T·ªïng failed</div>
                <div class="metric-value">{total_failed}</div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # Grid 2: Ph√¢n lo·∫°i l·ªói v√† t·ª∑ l·ªá
        st.markdown(f"""
        <div class="dashboard-grid">
            <div class="metric-card">
                <div class="metric-label">üìä T·ª∑ l·ªá pass t·ªïng</div>
                <div class="metric-value">{overall_pass_rate:.1f}%</div>
            </div>
            <div class="metric-card metric-card-danger">
                <div class="metric-label">üî¥ API Errors</div>
                <div class="metric-value">{total_api_errors}</div>
            </div>
            <div class="metric-card metric-card-warning">
                <div class="metric-label">üü° Extract Errors</div>
                <div class="metric-value">{total_extract_errors}</div>
            </div>
            <div class="metric-card metric-card-warning">
                <div class="metric-label">üü† Accuracy Errors</div>
                <div class="metric-value">{total_accuracy_errors}</div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # Bi·ªÉu ƒë·ªì ph√¢n b·ªë l·ªói
        if total_failed > 0:
            st.write("### üìà Ph√¢n b·ªë l·ªói")
            error_data = {
                'Lo·∫°i l·ªói': ['API Error', 'Extract Error', 'Accuracy < 8'],
                'S·ªë l∆∞·ª£ng': [total_api_errors, total_extract_errors, total_accuracy_errors],
                'T·ª∑ l·ªá %': [
                    (total_api_errors / total_failed) * 100,
                    (total_extract_errors / total_failed) * 100,
                    (total_accuracy_errors / total_failed) * 100
                ]
            }
            error_df = pd.DataFrame(error_data)
            st.dataframe(error_df, use_container_width=True)
    
    st.write("### üìã L·ªãch s·ª≠ test")
    if site in st.session_state.test_history and st.session_state.test_history[site]:
        history_df = pd.DataFrame(st.session_state.test_history[site])
        
        # Hi·ªÉn th·ªã dataframe v·ªõi kh·∫£ nƒÉng ch·ªçn d√≤ng
        selected_history = st.dataframe(
            history_df, 
            use_container_width=True,
            hide_index=True,
            on_select="rerun",
            selection_mode="single-row",
            key="history_selection"
        )
        
        # Hi·ªÉn th·ªã chi ti·∫øt k·∫øt qu·∫£ n·∫øu c√≥ d√≤ng ƒë∆∞·ª£c ch·ªçn
        if selected_history.selection.rows:
            selected_row_index = selected_history.selection.rows[0]
            selected_test = st.session_state.test_history[site][selected_row_index]
            
            st.write("### Chi ti·∫øt k·∫øt qu·∫£ test")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("T√™n test", selected_test.get('test_name', 'N/A'))
                st.metric("S·ªë c√¢u h·ªèi", selected_test.get('num_questions', 0))
            
            with col2:
                st.metric("‚úÖ Passed", selected_test.get('num_passed', 0))
                st.metric("‚ùå Failed", selected_test.get('num_failed', 0))
            
            with col3:
                st.metric("Th·ªùi gian", selected_test.get('timestamp', 'N/A'))
                pass_rate = (selected_test.get('num_passed', 0) / selected_test.get('num_questions', 1)) * 100
                st.metric("T·ª∑ l·ªá pass", f"{pass_rate:.1f}%")
            
            # Hi·ªÉn th·ªã ph√¢n lo·∫°i l·ªói chi ti·∫øt
            st.write("### üìä Ph√¢n lo·∫°i l·ªói chi ti·∫øt")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("üî¥ API Error", selected_test.get('num_failed_api', 0))
            with col2:
                st.metric("üü° Extract Error", selected_test.get('num_failed_extract', 0))
            with col3:
                st.metric("üü† Accuracy < 8", selected_test.get('num_failed_accuracy', 0))
            with col4:
                total_failed = selected_test.get('num_failed', 0)
                if total_failed > 0:
                    api_rate = (selected_test.get('num_failed_api', 0) / total_failed) * 100
                    st.metric("API Error %", f"{api_rate:.1f}%")
            
            # Hi·ªÉn th·ªã file k·∫øt qu·∫£ n·∫øu c√≥
            if 'filename' in selected_test:
                st.write("### File k·∫øt qu·∫£")
                result_file_path = os.path.join(RESULTS_DIR, site, selected_test['filename'])
                
                if os.path.exists(result_file_path):
                    try:
                        result_df = pd.read_excel(result_file_path)
                        st.write(f"**File:** `{selected_test['filename']}` ({len(result_df)} d√≤ng)")
                        
                        # Hi·ªÉn th·ªã preview 10 d√≤ng ƒë·∫ßu ti√™n
                        st.write("**Preview k·∫øt qu·∫£:**")
                        st.dataframe(result_df.head(10), use_container_width=True)
                        
                        # N√∫t t·∫£i xu·ªëng
                        with open(result_file_path, "rb") as f:
                            st.download_button(
                                label="üì• T·∫£i xu·ªëng file k·∫øt qu·∫£",
                                data=f.read(),
                                file_name=selected_test['filename'],
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                key=f"download_{selected_test['timestamp']}"
                            )
                        
                        # Hi·ªÉn th·ªã b·∫£ng c√°c c√¢u fail v·ªõi ph√¢n lo·∫°i
                        st.write("### üîç Chi ti·∫øt c√°c c√¢u fail")
                        
                        # ƒê·ªçc file k·∫øt qu·∫£ ƒë·ªÉ l·∫•y chi ti·∫øt
                        try:
                            result_df = pd.read_excel(result_file_path)
                            
                            # T·∫°o b·∫£ng fail v·ªõi ph√¢n lo·∫°i
                            failed_rows = []
                            for idx, row in result_df.iterrows():
                                if 'failed_details' in str(row.to_dict()):
                                    # Parse failed_details t·ª´ string n·∫øu c·∫ßn
                                    failed_details = row.get('failed_details', {})
                                    if isinstance(failed_details, str):
                                        try:
                                            import ast
                                            failed_details = ast.literal_eval(failed_details)
                                        except:
                                            failed_details = {}
                                    
                                    reason = failed_details.get('reason', 'Unknown')
                                    error_type = "üî¥ API Error" if "API" in reason or "Exception" in reason else \
                                               "üü° Extract Error" if "evaluate_result" in reason else \
                                               "üü† Accuracy < 8" if "Accuracy" in reason else "‚ùì Unknown"
                                    
                                    failed_rows.append({
                                        'C√¢u h·ªèi': row.get('question', 'N/A')[:100] + '...' if len(str(row.get('question', ''))) > 100 else row.get('question', 'N/A'),
                                        'Lo·∫°i l·ªói': error_type,
                                        'L√Ω do': reason,
                                        'Accuracy': row.get('accuracy', 0) if 'accuracy' in str(row) else 'N/A',
                                        'Average': row.get('average', 0) if 'average' in str(row) else 'N/A'
                                    })
                            
                            if failed_rows:
                                failed_df = pd.DataFrame(failed_rows)
                                st.dataframe(failed_df, use_container_width=True)
                            else:
                                st.info("Kh√¥ng c√≥ c√¢u n√†o fail trong test n√†y")
                                
                        except Exception as e:
                            st.error(f"L·ªói khi ƒë·ªçc chi ti·∫øt fail: {str(e)}")
                            
                    except Exception as e:
                        st.error(f"L·ªói khi ƒë·ªçc file k·∫øt qu·∫£: {str(e)}")
                else:
                    st.warning("File k·∫øt qu·∫£ kh√¥ng t·ªìn t·∫°i")
    else:
        st.info(f"Ch∆∞a c√≥ l·ªãch s·ª≠ test n√†o cho site {site}")
        
    # st.write("### Test cases th·∫•t b·∫°i")
    # if site in st.session_state.failed_tests and st.session_state.failed_tests[site]:
    #     failed_df = pd.DataFrame(st.session_state.failed_tests[site])
        
    #     # Hi·ªÉn th·ªã dataframe v·ªõi kh·∫£ nƒÉng ch·ªçn d√≤ng
    #     selected_failed = st.dataframe(
    #         failed_df, 
    #         use_container_width=True,
    #         hide_index=True,
    #         on_select="rerun",
    #         selection_mode="single-row",
    #         key="failed_selection"
    #     )
        
    #     # Hi·ªÉn th·ªã chi ti·∫øt test case th·∫•t b·∫°i n·∫øu c√≥ d√≤ng ƒë∆∞·ª£c ch·ªçn
    #     if selected_failed.selection.rows:
    #         selected_row_index = selected_failed.selection.rows[0]
    #         selected_failed_test = st.session_state.failed_tests[site][selected_row_index]
            
    #         st.write("### Chi ti·∫øt test case th·∫•t b·∫°i")
            
    #         # Hi·ªÉn th·ªã th√¥ng tin c∆° b·∫£n
    #         col1, col2 = st.columns(2)
            
    #         with col1:
    #             st.write("**Th√¥ng tin test:**")
    #             st.write(f"- **C√¢u h·ªèi:** {selected_failed_test.get('question', 'N/A')}")
    #             st.write(f"- **Chat ID:** {selected_failed_test.get('chat_id', 'N/A')}")
            
    #         with col2:
    #             st.write("**K·∫øt qu·∫£ ƒë√°nh gi√°:**")
    #             scores = selected_failed_test.get('evaluate_result', {}).get('scores', {})
    #             for metric, score in scores.items():
    #                 st.write(f"- **{metric}:** {score}")
            
    #         # Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi
    #         st.write("**C√¢u tr·∫£ l·ªùi chu·∫©n:**")
    #         st.text_area("True Answer", value=selected_failed_test.get('true_answer', ''), height=100, disabled=True)
            
    #         st.write("**C√¢u tr·∫£ l·ªùi t·ª´ Agent:**")
    #         st.text_area("Agent Answer", value=selected_failed_test.get('site_response', ''), height=100, disabled=True)
            
    #         # Hi·ªÉn th·ªã nh·∫≠n x√©t
    #         comments = selected_failed_test.get('evaluate_result', {}).get('comments', '')
    #         if comments:
    #             st.write("**Nh·∫≠n x√©t v√† g√≥p √Ω:**")
    #             st.text_area("Comments", value=comments, height=100, disabled=True)
            
    #         # Hi·ªÉn th·ªã th√¥ng tin l·ªói n·∫øu c√≥
    #         failed_details = selected_failed_test.get('failed_details', {})
    #         if failed_details:
    #             st.write("**Chi ti·∫øt l·ªói:**")
    #             st.write(f"- **Th·ªùi gian:** {failed_details.get('timestamp', 'N/A')}")
    #             st.write(f"- **T√™n test:** {failed_details.get('test_name', 'N/A')}")
    #             st.write(f"- **L√Ω do:** {failed_details.get('reason', 'N/A')}")
    #             if 'error_message' in failed_details:
    #                 st.write(f"- **Th√¥ng b√°o l·ªói:** {failed_details['error_message']}")
    # else:
    #     st.info("Ch∆∞a c√≥ test case th·∫•t b·∫°i n√†o")

    # st.write("### K·∫øt qu·∫£ ƒë√£ l∆∞u")
    # site_results_dir = os.path.join(RESULTS_DIR, site)
    # if os.path.exists(site_results_dir):
    #     try:
    #         all_files = [f for f in os.listdir(site_results_dir) if f.lower().endswith((".xlsx", ".xls"))]
    #     except Exception as e:
    #         all_files = []
    #         st.error(f"L·ªói khi li·ªát k√™ file k·∫øt qu·∫£: {str(e)}")

    #     if all_files:
    #         selected_file = st.selectbox("Ch·ªçn file k·∫øt qu·∫£ ƒë·ªÉ xem", sorted(all_files, reverse=True), key="saved_result_select")
    #         selected_path = os.path.join(site_results_dir, selected_file)
    #         cols = st.columns([1, 1])
    #         with cols[0]:
    #             if st.button("Xem preview 5 d√≤ng ƒë·∫ßu", key="preview_saved_result"):
    #                 try:
    #                     df_saved = pd.read_excel(selected_path)
    #                     st.write(f"File: `{selected_file}` ({len(df_saved)} d√≤ng)")
    #                     st.dataframe(df_saved.head(5), use_container_width=True)
    #                 except Exception as e:
    #                     st.error(f"L·ªói khi ƒë·ªçc file k·∫øt qu·∫£: {str(e)}")
    #         with cols[1]:
    #             try:
    #                 with open(selected_path, "rb") as f:
    #                     st.download_button(
    #                         label="T·∫£i xu·ªëng file k·∫øt qu·∫£",
    #                         data=f.read(),
    #                         file_name=selected_file,
    #                         mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    #                         key="download_saved_result"
    #                     )
    #             except Exception as e:
    #                 st.error(f"L·ªói khi m·ªü file ƒë·ªÉ t·∫£i xu·ªëng: {str(e)}")
    #     else:
    #         st.info("Ch∆∞a c√≥ file k·∫øt qu·∫£ n√†o ƒë∆∞·ª£c l∆∞u cho site n√†y.")
    # else:
    #     st.info("Th∆∞ m·ª•c k·∫øt qu·∫£ cho site n√†y ch∆∞a ƒë∆∞·ª£c t·∫°o.")

with tab5:
    # Custom CSS cho tab Qu·∫£n l√Ω Prompts
    st.markdown("""
    <style>
    /* Styling cho buttons */
    .stButton > button {
        border-radius: 8px;
        font-weight: 500;
        transition: all 0.3s ease;
        border: 1px solid #e0e0e0;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
    }
    
    /* Styling cho text areas */
    .stTextArea textarea {
        border-radius: 8px;
        border: 2px solid #e0e0e0;
        font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
        font-size: 13px;
    }
    
    .stTextArea textarea:focus {
        border-color: #4CAF50;
        box-shadow: 0 0 0 2px rgba(76, 175, 80, 0.2);
    }
    
    /* Spacing cho columns */
    .row-widget.stHorizontal {
        gap: 15px;
    }
    
    /* Styling cho headers */
    h3 {
        color: #1f77b4;
        border-bottom: 2px solid #1f77b4;
        padding-bottom: 8px;
        margin-top: 20px;
    }
    
    /* Card-like containers */
    .stExpander {
        border: 1px solid #e0e0e0;
        border-radius: 8px;
        margin-bottom: 10px;
    }
    
    /* Info boxes */
    .stAlert {
        border-radius: 8px;
    }
    
    /* Dataframe styling */
    .dataframe {
        border-radius: 8px;
        overflow: hidden;
    }
    
    /* Button container spacing */
    div[data-testid="column"] {
        padding: 5px;
    }
    
    /* Primary button highlight */
    .stButton > button[kind="primary"] {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
    }
    
    .stButton > button[kind="primary"]:hover {
        background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);
    }
    </style>
    """, unsafe_allow_html=True)
    
    st.subheader("Qu·∫£n l√Ω Prompts v√† Extract Sections")
    
    site = get_current_site()
    st.write(f"**Site hi·ªán t·∫°i:** {site}")
    
    # Load current prompts
    # Check if we need to force reload from file (reset button was clicked)
    if st.session_state.get('prompt_reset_trigger', False):
        prompts = load_prompts_for_site(site)
        st.session_state.prompt_reset_trigger = False
    else:
        prompts = load_prompts_for_site(site)
    
    current_extract_code = load_extract_sections_for_site(site)
    
    # Prompt Management Section
    st.write("### üìù Qu·∫£n l√Ω Prompts")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**System Prompt**")
        system_prompt = st.text_area(
            "System Prompt", 
            value=prompts["system_prompt"], 
            height=300,
            key="system_prompt_editor"
        )
    
    with col2:
        st.write("**Human Prompt**")
        human_prompt = st.text_area(
            "Human Prompt", 
            value=prompts["human_prompt"], 
            height=300,
            key="human_prompt_editor"
        )
    
    # Save prompts button v·ªõi styling ƒë·∫πp h∆°n
    st.write("")  # Spacing
    col1, col2, col3, col4 = st.columns([1, 1, 1, 3])
    with col1:
        if st.button("üíæ L∆∞u Prompts", key="save_prompts", use_container_width=True):
            if save_prompts_for_site(site, system_prompt, human_prompt):
                st.success("‚úÖ ƒê√£ l∆∞u prompts th√†nh c√¥ng!")
                # Clear any cached values
                if 'prompt_reset_trigger' in st.session_state:
                    del st.session_state.prompt_reset_trigger
                st.rerun()
            else:
                st.error("‚ùå L·ªói khi l∆∞u prompts!")
    
    with col2:
        if st.button("üîÑ Reset Prompts", key="reset_prompts", use_container_width=True):
            # Set a flag to trigger reload from file
            st.session_state.prompt_reset_trigger = True
            st.rerun()
    
    st.write("")  # Spacing
    
    # Extract Sections Management Section
    st.write("### üîß Qu·∫£n l√Ω Extract Sections")
    
    # T·ª± ƒë·ªông ph√¢n t√≠ch prompt v√† hi·ªÉn th·ªã mapping
    if system_prompt:
        # T·ª± ƒë·ªông ph√¢n t√≠ch prompt hi·ªán t·∫°i
        result = auto_generate_extract_sections_from_prompt(system_prompt)
        
        # Hi·ªÉn th·ªã mapping preview
        st.write("**Mapping ƒë∆∞·ª£c ph√°t hi·ªán t·ª´ System Prompt:**")
        
        # Hi·ªÉn th·ªã mapping table
        if result and result.get('normalized_criteria'):
            mapping_data = []
            for i, criterion in enumerate(result['normalized_criteria']):
                original_criterion = result['criteria'][i] if i < len(result['criteria']) else criterion
                description = result['descriptions'][i] if i < len(result['descriptions']) else ""
                
                # N·∫øu kh√¥ng c√≥ description t·ª´ prompt, d√πng m√¥ t·∫£ m·∫∑c ƒë·ªãnh
                if not description:
                    if 'relevance' in criterion:
                        description = 'M·ª©c ƒë·ªô li√™n quan ƒë·∫øn c√¢u h·ªèi'
                    elif 'accuracy' in criterion:
                        description = 'ƒê·ªô ch√≠nh x√°c c·ªßa th√¥ng tin'
                    elif 'completeness' in criterion:
                        description = 'T√≠nh ƒë·∫ßy ƒë·ªß c·ªßa c√¢u tr·∫£ l·ªùi'
                    elif 'access_control' in criterion:
                        description = 'Ki·ªÉm so√°t truy c·∫≠p v√† b·∫£o m·∫≠t'
                    elif 'clarity' in criterion:
                        description = 'T√≠nh r√µ r√†ng v√† d·ªÖ hi·ªÉu'
                    elif 'tone' in criterion:
                        description = 'Gi·ªçng ƒëi·ªáu v√† th√°i ƒë·ªô'
                    else:
                        description = 'Ti√™u ch√≠ kh√°c'
                
                mapping_data.append({
                    'Ti√™u ch√≠ trong Prompt': original_criterion,
                    'Key trong JSON': criterion,
                    'M√¥ t·∫£': description
                })
            
            mapping_df = pd.DataFrame(mapping_data)
            st.dataframe(mapping_df, use_container_width=True)
        else:
            st.warning("Kh√¥ng t√¨m th·∫•y ti√™u ch√≠ n√†o trong System Prompt")
        
        st.write("")  # Spacing
        col1, col2, col3, col4 = st.columns([1, 1, 1, 3])
        with col1:
            if st.button("üíæ L∆∞u Extract Code", key="save_extract", use_container_width=True):
                extract_code = result['code']
                # L∆∞u lu√¥n v√†o file
                if save_extract_sections_for_site(site, extract_code):
                    st.success("‚úÖ ƒê√£ l∆∞u extract sections th√†nh c√¥ng!")
                    st.rerun()
                else:
                    st.error("‚ùå L·ªói khi l∆∞u extract sections!")
        with col2:
            if st.button("üîÑ Reset Extract Code", key="reset_extract", use_container_width=True):
                current_extract_code = load_extract_sections_for_site(site)
                st.rerun()
    else:
        st.info("‚ö†Ô∏è Vui l√≤ng nh·∫≠p System Prompt ƒë·ªÉ t·ª± ƒë·ªông t·∫°o Extract Sections")
    
    # Preview Section
    st.write("### üëÅÔ∏è Preview")
    
    with st.container():
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**System Prompt Preview**")
            if system_prompt:
                preview_text = system_prompt[:500] + "..." if len(system_prompt) > 500 else system_prompt
                st.text_area("Preview", value=preview_text, height=150, disabled=True, key="system_preview", label_visibility="collapsed")
                st.caption(f"üìù {len(system_prompt)} k√Ω t·ª±")
            else:
                st.info("Ch∆∞a c√≥ system prompt")
        
        with col2:
            st.write("**Human Prompt Preview**")
            if human_prompt:
                preview_text = human_prompt[:500] + "..." if len(human_prompt) > 500 else human_prompt
                st.text_area("Preview", value=preview_text, height=150, disabled=True, key="human_preview", label_visibility="collapsed")
                st.caption(f"üìù {len(human_prompt)} k√Ω t·ª±")
            else:
                st.info("Ch∆∞a c√≥ human prompt")
    
    # # File Information
    # st.write("### üìÅ Th√¥ng tin Files")
    
    # prompt_paths = get_prompt_paths(site)
    # extract_path = get_extract_sections_path(site)
    
    # col1, col2, col3 = st.columns(3)
    
    # with col1:
    #     st.write("**System Prompt**")
    #     st.code(f"üìÑ {prompt_paths['system_prompt']}")
    #     if os.path.exists(prompt_paths["system_prompt"]):
    #         file_size = os.path.getsize(prompt_paths["system_prompt"])
    #         st.write(f"üìä K√≠ch th∆∞·ªõc: {file_size} bytes")
    #     else:
    #         st.warning("‚ö†Ô∏è File kh√¥ng t·ªìn t·∫°i")
    
    # with col2:
    #     st.write("**Human Prompt**")
    #     st.code(f"üìÑ {prompt_paths['human_prompt']}")
    #     if os.path.exists(prompt_paths["human_prompt"]):
    #         file_size = os.path.getsize(prompt_paths["human_prompt"])
    #         st.write(f"üìä K√≠ch th∆∞·ªõc: {file_size} bytes")
    #     else:
    #         st.warning("‚ö†Ô∏è File kh√¥ng t·ªìn t·∫°i")
    
    # with col3:
    #     st.write("**Extract Sections**")
    #     st.code(f"üêç {extract_path}")
    #     if os.path.exists(extract_path):
    #         file_size = os.path.getsize(extract_path)
    #         st.write(f"üìä K√≠ch th∆∞·ªõc: {file_size} bytes")
    #     else:
    #         st.warning("‚ö†Ô∏è File kh√¥ng t·ªìn t·∫°i")
    
    # # Instructions
    # st.write("### üìã H∆∞·ªõng d·∫´n")
    # st.markdown("""
    # **Qu·∫£n l√Ω Prompts:**
    # - System Prompt: ƒê·ªãnh nghƒ©a vai tr√≤ v√† ti√™u ch√≠ ƒë√°nh gi√° cho LLM
    # - Human Prompt: Template cho input ƒë∆∞·ª£c g·ª≠i ƒë·∫øn LLM
    # - S·ª≠ d·ª•ng `{question}`, `{true_answer}`, `{agent_answer}` l√†m placeholders
    
    # **Qu·∫£n l√Ω Extract Sections:**
    # - Code Python ƒë·ªÉ tr√≠ch xu·∫•t k·∫øt qu·∫£ t·ª´ response c·ªßa LLM
    # - Ph·∫£i c√≥ function `extract_section(text)` tr·∫£ v·ªÅ dict v·ªõi keys: `scores` v√† `comments`
    # - `scores` ph·∫£i ch·ª©a c√°c metrics ph√π h·ª£p v·ªõi site (THFC c√≥ access_control, HR c√≥ tone)
    # - **ü§ñ T·ª± ƒë·ªông t·∫°o**: Nh·∫•n "T·ª± ƒë·ªông t·∫°o t·ª´ Prompt" ƒë·ªÉ AI ph√¢n t√≠ch system prompt v√† t·∫°o code ph√π h·ª£p
    
    # **L∆∞u √Ω:**
    # - Sau khi l∆∞u, c√°c thay ƒë·ªïi s·∫Ω c√≥ hi·ªáu l·ª±c ngay l·∫≠p t·ª©c
    # - Backup files tr∆∞·ªõc khi ch·ªânh s·ª≠a ƒë·ªÉ tr√°nh m·∫•t d·ªØ li·ªáu
    # - Ki·ªÉm tra syntax Python tr∆∞·ªõc khi l∆∞u extract sections
    # - T√≠nh nƒÉng t·ª± ƒë·ªông t·∫°o s·∫Ω ph√¢n t√≠ch c√°c ti√™u ch√≠ trong system prompt v√† t·∫°o code t∆∞∆°ng ·ª©ng
    # """)

# Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng
st.sidebar.subheader("H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng")
st.sidebar.markdown("""
### Test ƒë∆°n l·∫ª
1. Nh·∫≠p c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi chu·∫©n.
2. Nh·∫•n "Test" ƒë·ªÉ xem k·∫øt qu·∫£.

### Test h√†ng lo·∫°t
1. T·∫£i file Excel.
2. Ch·ªçn c√°c c√¢u h·ªèi mu·ªën test.
3. Nh·∫•n "Test h√†ng lo·∫°t".

### L·∫≠p l·ªãch test
1. T·∫£i file test v√† ƒë·∫∑t t√™n.
2. Thi·∫øt l·∫≠p l·ªãch v√† nh·∫•n "Thi·∫øt l·∫≠p l·ªãch".

### Qu·∫£n l√Ω test
1. Xem l·ªãch s·ª≠ v√† c√°c test case th·∫•t b·∫°i.

### Qu·∫£n l√Ω Prompts
1. Ch·ªânh s·ª≠a system prompt v√† human prompt.
2. C·∫≠p nh·∫≠t extract sections code.
3. L∆∞u ƒë·ªÉ √°p d·ª•ng thay ƒë·ªïi.
""")
