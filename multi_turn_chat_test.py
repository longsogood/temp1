import streamlit as st
import requests
import json
import time
import pandas as pd
import concurrent.futures
import os
import multiprocessing
from utils import extract_section
from streamlit.runtime.scriptrunner_utils.script_run_context import add_script_run_ctx, get_script_run_ctx
import queue
from uuid import uuid4
from threading import Lock
import warnings
import pickle
warnings.filterwarnings("ignore")

# Kh·ªüi t·∫°o session state n·∫øu ch∆∞a c√≥
if 'results' not in st.session_state:
    st.session_state.results = None
if 'results_df' not in st.session_state:
    st.session_state.results_df = None
if 'filtered_df' not in st.session_state:
    st.session_state.filtered_df = None
if 'filter_applied' not in st.session_state:
    st.session_state.filter_applied = False

# H√†m callback ƒë·ªÉ l·ªçc k·∫øt qu·∫£
def filter_results():
    if st.session_state.results_df is not None:
        selected_criterion = st.session_state.selected_criterion
        threshold = st.session_state.threshold
        filter_type = st.session_state.filter_type
        
        # L·ªçc DataFrame d·ª±a tr√™n ti√™u ch√≠ ƒë√£ ch·ªçn
        if filter_type == "L·ªõn h∆°n ho·∫∑c b·∫±ng":
            st.session_state.filtered_df = st.session_state.results_df[st.session_state.results_df[selected_criterion] >= threshold]
        else:
            st.session_state.filtered_df = st.session_state.results_df[st.session_state.results_df[selected_criterion] <= threshold]
        
        st.session_state.filter_applied = True

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="VƒÉn ph√≤ng ch√≠nh ph·ªß Agent Multi-Turn Testing",
    page_icon="ü§ñ",
    layout="wide"
)
GENERAL_PURPOSE_API_URL = st.text_input("GENERAL_PURPOSE_API_URL")
VPCP_API_URL = st.text_input("VPCP_API_URL")

# T·ª± ƒë·ªông x√°c ƒë·ªãnh s·ªë workers t·ªëi ∆∞u
CPU_COUNT = multiprocessing.cpu_count()
MAX_WORKERS = min(int(CPU_COUNT * 0.75), 8)  # S·ª≠ d·ª•ng 75% s·ªë CPU cores, nh∆∞ng kh√¥ng qu√° 8 workers
MAX_WORKERS = max(MAX_WORKERS, 2)  # ƒê·∫£m b·∫£o c√≥ √≠t nh·∫•t 2 workers

# T·∫°o session ƒë·ªÉ t√°i s·ª≠ d·ª•ng k·∫øt n·ªëi
session = requests.Session()
session.mount('https://', requests.adapters.HTTPAdapter(
    max_retries=3,
    pool_connections=MAX_WORKERS,
    pool_maxsize=MAX_WORKERS
))

# Load prompts
try:
    # evaluate_prompt = json.load(open("prompts/evaluation/prompt.json", "r"))
    evaluate_system_prompt = open("prompts/evaluation/system_prompt.txt").read()
    evaluate_human_prompt_template = open("prompts/evaluation/system_prompt.txt").read()
except Exception as e:
    st.error(f"L·ªói khi ƒë·ªçc file prompt: {str(e)}")
    st.stop()

# Th√™m bi·∫øn to√†n c·ª•c ƒë·ªÉ l∆∞u tr·ªØ ti·∫øn tr√¨nh
progress_queue = queue.Queue()
progress_lock = Lock()

def update_progress(progress_container, total_questions):
    """C·∫≠p nh·∫≠t ti·∫øn tr√¨nh t·ª´ queue"""
    while True:
        try:
            message = progress_queue.get_nowait()
            with progress_container.container():
                if message.startswith("SUCCESS"):
                    st.success(message[7:])
                elif message.startswith("ERROR"):
                    st.error(message[5:])
                else:
                    st.info(message)
        except queue.Empty:
            break

def query_with_retry(url, payload, max_retries=3, delay=1):
    for attempt in range(max_retries):
        try:
            print("ƒêang g·ªçi API...")
            response = session.post(url, json=payload, timeout=120)
            response.raise_for_status()
            return response
        except requests.exceptions.RequestException as e:
            if attempt == max_retries - 1:
                raise
            time.sleep(delay * (attempt + 1))
    return None

def process_chat_session(chat_questions, chat_answers, chat_refs, chat_id, index, total_chats):
    try:
        session_id = str(uuid4())
        chat_results = []
        
        progress_queue.put(f"INFO B·∫Øt ƒë·∫ßu x·ª≠ l√Ω phi√™n chat {index + 1}/{total_chats} (ID: {chat_id})")
        
        # X·ª≠ l√Ω t·ª´ng c√¢u h·ªèi trong phi√™n chat
        for i, (question, true_answer, ref) in enumerate(zip(chat_questions, chat_answers, chat_refs)):
            progress_queue.put(f"INFO ƒêang x·ª≠ l√Ω c√¢u h·ªèi {i + 1}/{len(chat_questions)} trong phi√™n chat {index + 1}")
            
            # G·ª≠i c√¢u h·ªèi ƒë·∫øn API
            vpcp_response = query_with_retry(VPCP_API_URL,
                                          {"question": question,
                                           "overrideConfig": {
                                               "sessionId": session_id
                                           }})
            if not vpcp_response:
                progress_queue.put(f"ERROR L·ªói khi l·∫•y c√¢u tr·∫£ l·ªùi t·ª´ agent cho c√¢u h·ªèi {i + 1} trong phi√™n chat {index + 1}")
                continue
                
            vpcp_response = vpcp_response.json()["text"]
            
            # ƒê√°nh gi√° c√¢u tr·∫£ l·ªùi
            evaluate_human_prompt = evaluate_human_prompt_template.format(
                question=question,
                true_answer=true_answer,
                agent_answer=vpcp_response
            )
            
            payload = {
                "question": "ƒê√°nh gi√° c√¢u tr·∫£ l·ªùi t·ª´ agent so v·ªõi c√¢u tr·∫£ l·ªùi chu·∫©n (true_answer)",
                "overrideConfig": {
                        "systemMessagePrompt": evaluate_system_prompt,
                        "humanMessagePrompt": evaluate_human_prompt
                    }
            }
            
            evaluate_response = query_with_retry(GENERAL_PURPOSE_API_URL, payload)
            if not evaluate_response:
                progress_queue.put(f"ERROR L·ªói khi ƒë√°nh gi√° c√¢u tr·∫£ l·ªùi cho c√¢u h·ªèi {i + 1} trong phi√™n chat {index + 1}")
                continue
                
            evaluate_response = evaluate_response.json()["text"]
            
            try:
                evaluate_result = extract_section(evaluate_response)
                print(f"K·∫øt qu·∫£ ƒë√°nh gi√° c√¢u h·ªèi {i + 1} trong phi√™n chat {index + 1}: {evaluate_result}")
            except Exception as e:
                progress_queue.put(f"ERROR L·ªói khi tr√≠ch xu·∫•t k·∫øt qu·∫£ ƒë√°nh gi√°: {str(e)}")
                continue
            
            # L∆∞u k·∫øt qu·∫£ c·ªßa c√¢u h·ªèi
            chat_results.append({
                "session_id": session_id,
                "chat_id": chat_id,
                "question_index": i + 1,
                "question": question,
                "true_answer": true_answer,
                "vpcp_response": vpcp_response,
                "evaluate_result": evaluate_result,
                "ref": ref
            })
            
            progress_queue.put(f"SUCCESS ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng c√¢u h·ªèi {i + 1}/{len(chat_questions)} trong phi√™n chat {index + 1}")
        
        progress_queue.put(f"SUCCESS ƒê√£ ho√†n th√†nh phi√™n chat {index + 1}/{total_chats} (ID: {chat_id})")
        return chat_results
    except Exception as e:
        progress_queue.put(f"ERROR L·ªói khi x·ª≠ l√Ω phi√™n chat {index + 1}: {str(e)}")
        print(f"L·ªói khi x·ª≠ l√Ω phi√™n chat {index + 1}: {str(e)}")
        return []

def process_chat_sessions_batch(chat_sessions):
    all_results = []
    failed_chats = []
    
    # T·∫°o container cho ti·∫øn tr√¨nh
    progress_container = st.empty()
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = []
        
        for i, (chat_id, chat_data) in enumerate(chat_sessions.items()):
            chat_questions = [item["question"] for item in chat_data]
            chat_answers = [item["answer"] for item in chat_data]
            chat_refs = [item["ref"] for item in chat_data]
            
            future = executor.submit(process_chat_session, chat_questions, chat_answers, chat_refs, chat_id, i, len(chat_sessions))
            futures.append(future)
        
        # Hi·ªÉn th·ªã ti·∫øn tr√¨nh t·ªïng th·ªÉ
        progress_queue.put(f"ƒêang x·ª≠ l√Ω {len(chat_sessions)} phi√™n chat...")
        
        # C·∫≠p nh·∫≠t ti·∫øn tr√¨nh trong khi ch·ªù k·∫øt qu·∫£
        while not all(future.done() for future in futures):
            update_progress(progress_container, len(chat_sessions))
            time.sleep(0.1)
        
        # C·∫≠p nh·∫≠t l·∫ßn cu·ªëi
        update_progress(progress_container, len(chat_sessions))
        
        for i, future in enumerate(futures):
            try:
                result = future.result()
                if result:
                    all_results.extend(result)
            except Exception as e:
                st.error(f"L·ªói khi thu th·∫≠p k·∫øt qu·∫£ t·ª´ phi√™n chat {i + 1}: {str(e)}")
                failed_chats.append((i, str(e)))
    
    return all_results, failed_chats

# Giao di·ªán Streamlit
st.title("ü§ñ VPCP Agent Multi-Turn Testing")

st.subheader("Test phi√™n chat t·ª´ file Excel")

# Th√™m ch·ª©c nƒÉng t·∫£i l√™n file
uploaded_file = st.file_uploader("Ch·ªçn file Excel", type=['xlsx', 'xls'])

if uploaded_file is not None:
    try:
        df = pd.read_excel(uploaded_file)
        
        # Ki·ªÉm tra c·∫•u tr√∫c file Excel
        required_columns = ["chat_script_id", "qa_id", "question", "answer", "ref"]
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            st.error(f"File Excel thi·∫øu c√°c c·ªôt: {', '.join(missing_columns)}")
            st.stop()
        
        # Nh√≥m d·ªØ li·ªáu theo chat_script_id
        chat_sessions = {}
        for chat_id, group in df.groupby("chat_script_id"):
            chat_sessions[chat_id] = []
            # S·∫Øp x·∫øp theo qa_id ƒë·ªÉ ƒë·∫£m b·∫£o th·ª© t·ª± ƒë√∫ng
            sorted_group = group.sort_values("qa_id")
            for _, row in sorted_group.iterrows():
                chat_sessions[chat_id].append({
                    "question": row["question"],
                    "answer": row["answer"],
                    "ref": row["ref"]
                })
        
        # Hi·ªÉn th·ªã danh s√°ch c√°c phi√™n chat
        st.write(f"T√¨m th·∫•y {len(chat_sessions)} phi√™n chat")
        
        # T·∫°o DataFrame ƒë·ªÉ hi·ªÉn th·ªã
        chat_summary = []
        for chat_id, questions in chat_sessions.items():
            chat_summary.append({
                "Chat ID": chat_id,
                "S·ªë c√¢u h·ªèi": len(questions),
                "C√¢u h·ªèi ƒë·∫ßu ti√™n": questions[0]["question"][:100] + "..." if len(questions[0]["question"]) > 100 else questions[0]["question"]
            })
        
        chat_summary_df = pd.DataFrame(chat_summary)
        
        # Hi·ªÉn th·ªã b·∫£ng c√≥ th·ªÉ ch·ªçn
        edited_df = st.dataframe(
            chat_summary_df,
            use_container_width=True,
            selection_mode="multi-row",
            on_select="rerun",
            hide_index=True
        )
        
        # L·∫•y c√°c phi√™n chat ƒë√£ ch·ªçn
        selected_rows = edited_df['selection']['rows']
        selected_chat_ids = [chat_summary_df.iloc[row]["Chat ID"] for row in selected_rows]
        
        # T·∫°o dict ch·ªâ ch·ª©a c√°c phi√™n chat ƒë√£ ch·ªçn
        selected_chat_sessions = {chat_id: chat_sessions[chat_id] for chat_id in selected_chat_ids if chat_id in chat_sessions}
        
        if st.button("Test phi√™n chat"):
            if len(selected_chat_sessions) > 0:
                # X·ª≠ l√Ω ƒëa lu·ªìng
                results, failed_chats = process_chat_sessions_batch(selected_chat_sessions)
                
                if results:
                    # L∆∞u k·∫øt qu·∫£ v√†o session state
                    st.session_state.results = results
                    
                    with open("chat_results.pkl", "wb") as f:
                        pickle.dump(results, f)
                    
                    # T·∫°o DataFrame t·ª´ k·∫øt qu·∫£
                    data = {
                        'Chat ID': [r["chat_id"] for r in results],
                        'Question Index': [r["question_index"] for r in results],
                        'Question': [r["question"] for r in results],
                        'True Answer': [r["true_answer"] for r in results],
                        'Agent Answer': [r["vpcp_response"] for r in results],
                        'Ref': [r["ref"] for r in results],
                        'Session ID': [r["session_id"] for r in results],
                        'Information Coverage Score': [r["evaluate_result"]["scores"].get("information_coverage", 0) for r in results],
                        'Hallucination Score': [r["evaluate_result"]["scores"].get("hallucination_control", 0) for r in results],
                        'Format Score': [r["evaluate_result"]["scores"].get("format_and_structure", 0) for r in results],
                        'Language Score': [r["evaluate_result"]["scores"].get("language_and_style", 0) for r in results],
                        'Handling Unknown Score': [r["evaluate_result"]["scores"].get("handling_unknown", 0) for r in results],
                        'Average Score': [r["evaluate_result"]["scores"].get("average", 0) for r in results],
                        'Comment': [r["evaluate_result"].get("comments", "") for r in results]
                    }
                    
                    results_df = pd.DataFrame(data)
                    
                    # L∆∞u DataFrame v√†o session state
                    st.session_state.results_df = results_df
                    
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£
                    st.dataframe(results_df, use_container_width=True)
                    
                    # Th√™m n√∫t t·∫£i xu·ªëng k·∫øt qu·∫£
                    st.download_button(
                        label="T·∫£i xu·ªëng k·∫øt qu·∫£",
                        data=results_df.to_csv(index=False).encode('utf-8'),
                        file_name='chat_evaluation_results.csv',
                        mime='text/csv'
                    )
                    
                    # T√≠nh ƒëi·ªÉm trung b√¨nh cho m·ªói phi√™n chat
                    chat_avg_scores = results_df.groupby('Chat ID').agg({
                        'Information Coverage Score': 'mean',
                        'Hallucination Score': 'mean',
                        'Format Score': 'mean',
                        'Language Score': 'mean',
                        'Handling Unknown Score': 'mean',
                        'Average Score': 'mean'
                    }).reset_index()
                    
                    st.subheader("ƒêi·ªÉm trung b√¨nh theo phi√™n chat")
                    st.dataframe(chat_avg_scores, use_container_width=True)
                    
                    # Th√™m ph·∫ßn l·ªçc k·∫øt qu·∫£ theo ƒëi·ªÉm
                    st.subheader("L·ªçc k·∫øt qu·∫£ theo ƒëi·ªÉm")
                    
                    # S·ª≠ d·ª•ng form ƒë·ªÉ tr√°nh rerun t·ª± ƒë·ªông
                    with st.form(key='filter_form'):
                        # L·∫•y t·∫•t c·∫£ ti√™u ch√≠ ƒëi·ªÉm
                        score_columns = [col for col in results_df.columns if 'Score' in col]
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.selectbox("Ch·ªçn ti√™u ch√≠ ƒëi·ªÉm", score_columns, key='selected_criterion')
                        with col2:
                            st.slider("Ng∆∞·ª°ng ƒëi·ªÉm", 0.0, 10.0, 5.0, 0.5, key='threshold')
                        
                        st.radio("Lo·∫°i l·ªçc", ["L·ªõn h∆°n ho·∫∑c b·∫±ng", "Nh·ªè h∆°n ho·∫∑c b·∫±ng"], key='filter_type')
                        
                        # N√∫t submit form
                        submitted = st.form_submit_button("√Åp d·ª•ng b·ªô l·ªçc", on_click=filter_results)
                    
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£ ƒë√£ l·ªçc n·∫øu ƒë√£ √°p d·ª•ng b·ªô l·ªçc
                    if st.session_state.filter_applied and st.session_state.filtered_df is not None:
                        # Hi·ªÉn th·ªã k·∫øt qu·∫£ ƒë√£ l·ªçc
                        st.write(f"T√¨m th·∫•y {len(st.session_state.filtered_df)} k·∫øt qu·∫£ ph√π h·ª£p v·ªõi b·ªô l·ªçc")
                        st.dataframe(st.session_state.filtered_df, use_container_width=True)
                        
                        # T√πy ch·ªçn xu·∫•t k·∫øt qu·∫£ ƒë√£ l·ªçc
                        st.download_button(
                            label="T·∫£i xu·ªëng k·∫øt qu·∫£ ƒë√£ l·ªçc",
                            data=st.session_state.filtered_df.to_csv(index=False).encode('utf-8'),
                            file_name=f'filtered_chat_results_{st.session_state.selected_criterion}_{st.session_state.threshold}.csv',
                            mime='text/csv'
                        )
                    
                    if failed_chats:
                        st.warning(f"C√≥ {len(failed_chats)} phi√™n chat x·ª≠ l√Ω th·∫•t b·∫°i")
                else:
                    st.error("Kh√¥ng c√≥ k·∫øt qu·∫£ t·ª´ qu√° tr√¨nh x·ª≠ l√Ω")
            else:
                st.warning("Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt phi√™n chat ƒë·ªÉ test")
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc file Excel: {str(e)}")
else:
    st.info("Vui l√≤ng t·∫£i l√™n file Excel ƒë·ªÉ b·∫Øt ƒë·∫ßu")

# Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng
st.sidebar.subheader("H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng")
st.sidebar.markdown("""
### Test phi√™n chat
1. T·∫£i l√™n file Excel ch·ª©a d·ªØ li·ªáu phi√™n chat
2. Ch·ªçn c√°c phi√™n chat mu·ªën test t·ª´ b·∫£ng
3. Nh·∫•n n√∫t "Test phi√™n chat" ƒë·ªÉ b·∫Øt ƒë·∫ßu ƒë√°nh gi√°
4. K·∫øt qu·∫£ s·∫Ω ƒë∆∞·ª£c hi·ªÉn th·ªã d∆∞·ªõi d·∫°ng b·∫£ng v√† c√≥ th·ªÉ t·∫£i v·ªÅ Excel
5. B·∫°n c√≥ th·ªÉ xem ƒëi·ªÉm trung b√¨nh theo phi√™n chat v√† l·ªçc k·∫øt qu·∫£ theo ƒëi·ªÉm

### C·∫•u tr√∫c file Excel
File Excel c·∫ßn c√≥ c√°c c·ªôt sau:
- chat_script_id: ID c·ªßa phi√™n chat
- qa_id: ID c·ªßa c√¢u h·ªèi trong phi√™n chat
- question: N·ªôi dung c√¢u h·ªèi
- answer: C√¢u tr·∫£ l·ªùi chu·∫©n
- ref: Tham chi·∫øu (n·∫øu c√≥)
""")